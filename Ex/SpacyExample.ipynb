{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32205,
     "status": "ok",
     "timestamp": 1744959206801,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "2iBziwmskddV",
    "outputId": "332e859e-b5bb-4854-af5f-1f5b71ea2a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spaCy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spaCy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spaCy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spaCy)\n",
      "  Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spaCy)\n",
      "  Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spaCy)\n",
      "  Using cached preshed-3.0.9-cp313-cp313-win_amd64.whl\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spaCy)\n",
      "  Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spaCy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spaCy)\n",
      "  Using cached srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spaCy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spaCy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spaCy)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\fonta\\desktop\\uni\\repo\\nlp\\env\\lib\\site-packages (from spaCy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\fonta\\desktop\\uni\\repo\\nlp\\env\\lib\\site-packages (from spaCy) (2.2.4)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spaCy)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spaCy)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting jinja2 (from spaCy)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from spaCy)\n",
      "  Using cached setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fonta\\desktop\\uni\\repo\\nlp\\env\\lib\\site-packages (from spaCy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spaCy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spaCy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy)\n",
      "  Using cached pydantic_core-2.33.1-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spaCy)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spaCy)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spaCy)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spaCy)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.0->spaCy)\n",
      "  Using cached blis-1.3.0-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spaCy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\fonta\\desktop\\uni\\repo\\nlp\\env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spaCy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\fonta\\desktop\\uni\\repo\\nlp\\env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spaCy) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spaCy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spaCy)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spaCy)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spaCy)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spaCy)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spaCy)\n",
      "  Downloading marisa_trie-1.2.1-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\fonta\\desktop\\uni\\repo\\nlp\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (2.19.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spaCy)\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl (24 kB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.1-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached blis-1.3.0-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 4.5/5.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading marisa_trie-1.2.1-cp313-cp313-win_amd64.whl (149 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: spaCy\n",
      "  Building wheel for spaCy (pyproject.toml): started\n",
      "  Building wheel for spaCy (pyproject.toml): finished with status 'error'\n",
      "Failed to build spaCy\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for spaCy (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1812 lines of output]\n",
      "      Copied C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\setup.cfg -> C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\spacy\\tests\\package\n",
      "      Copied C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\pyproject.toml -> C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\spacy\\tests\\package\n",
      "      Cythonizing sources\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: MIT License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\about.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\compat.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\errors.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\git_info.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\glossary.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\language.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\lookups.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\pipe_analysis.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\schemas.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\scorer.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\ty.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\util.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\__main__.py -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\apply.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\assemble.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\benchmark_speed.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\convert.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\debug_config.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\debug_data.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\debug_diff.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\debug_model.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\download.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\evaluate.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\find_function.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\find_threshold.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\info.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\init_config.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\init_pipeline.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\package.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\pretrain.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\profile.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\train.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\validate.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\_util.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      copying spacy\\cli\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\displacy\n",
      "      copying spacy\\displacy\\render.py -> build\\lib.win-amd64-cpython-313\\spacy\\displacy\n",
      "      copying spacy\\displacy\\templates.py -> build\\lib.win-amd64-cpython-313\\spacy\\displacy\n",
      "      copying spacy\\displacy\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\displacy\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      copying spacy\\lang\\char_classes.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      copying spacy\\lang\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      copying spacy\\lang\\norm_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      copying spacy\\lang\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      copying spacy\\lang\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      copying spacy\\lang\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\callbacks.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\extract_ngrams.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\extract_spans.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\featureextractor.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\staticvectors.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\tb_framework.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\_character_embed.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\_precomputable_affine.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\attributeruler.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\edit_tree_lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\entityruler.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\entity_linker.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\functions.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\spancat.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\span_finder.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\span_ruler.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\textcat.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\textcat_multilabel.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\tok2vec.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\conftest.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\enable_gpu.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_architectures.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_cli.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_cli_app.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_displacy.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_errors.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_language.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_misc.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_models.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_pickles.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_scorer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\test_ty.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\tok2vec.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\util.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      copying spacy\\tests\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\underscore.py -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\_dict_proxies.py -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\_serialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\alignment.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\augment.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\batchers.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\callbacks.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\corpus.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\initialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\iob_utils.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\loggers.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\loop.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\pretrain.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\assets.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\clone.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\document.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\dvc.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\pull.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\push.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\remote_storage.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\run.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      copying spacy\\cli\\project\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\project\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\af\n",
      "      copying spacy\\lang\\af\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\af\n",
      "      copying spacy\\lang\\af\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\af\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      copying spacy\\lang\\am\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      copying spacy\\lang\\am\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      copying spacy\\lang\\am\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      copying spacy\\lang\\am\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      copying spacy\\lang\\am\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      copying spacy\\lang\\am\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\am\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      copying spacy\\lang\\ar\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      copying spacy\\lang\\ar\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      copying spacy\\lang\\ar\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      copying spacy\\lang\\ar\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      copying spacy\\lang\\ar\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      copying spacy\\lang\\ar\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ar\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\az\n",
      "      copying spacy\\lang\\az\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\az\n",
      "      copying spacy\\lang\\az\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\az\n",
      "      copying spacy\\lang\\az\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\az\n",
      "      copying spacy\\lang\\az\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\az\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\bg\n",
      "      copying spacy\\lang\\bg\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bg\n",
      "      copying spacy\\lang\\bg\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bg\n",
      "      copying spacy\\lang\\bg\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bg\n",
      "      copying spacy\\lang\\bg\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bg\n",
      "      copying spacy\\lang\\bg\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bg\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\bn\n",
      "      copying spacy\\lang\\bn\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bn\n",
      "      copying spacy\\lang\\bn\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bn\n",
      "      copying spacy\\lang\\bn\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bn\n",
      "      copying spacy\\lang\\bn\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bn\n",
      "      copying spacy\\lang\\bn\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bn\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\bo\n",
      "      copying spacy\\lang\\bo\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bo\n",
      "      copying spacy\\lang\\bo\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bo\n",
      "      copying spacy\\lang\\bo\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bo\n",
      "      copying spacy\\lang\\bo\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\bo\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      copying spacy\\lang\\ca\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ca\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\cs\n",
      "      copying spacy\\lang\\cs\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\cs\n",
      "      copying spacy\\lang\\cs\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\cs\n",
      "      copying spacy\\lang\\cs\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\cs\n",
      "      copying spacy\\lang\\cs\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\cs\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      copying spacy\\lang\\da\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\da\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      copying spacy\\lang\\de\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      copying spacy\\lang\\de\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      copying spacy\\lang\\de\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      copying spacy\\lang\\de\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      copying spacy\\lang\\de\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      copying spacy\\lang\\de\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\de\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\dsb\n",
      "      copying spacy\\lang\\dsb\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\dsb\n",
      "      copying spacy\\lang\\dsb\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\dsb\n",
      "      copying spacy\\lang\\dsb\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\dsb\n",
      "      copying spacy\\lang\\dsb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\dsb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\get_pos_from_wiktionary.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      copying spacy\\lang\\el\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\el\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      copying spacy\\lang\\en\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\en\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      copying spacy\\lang\\es\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\es\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\et\n",
      "      copying spacy\\lang\\et\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\et\n",
      "      copying spacy\\lang\\et\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\et\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\eu\n",
      "      copying spacy\\lang\\eu\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\eu\n",
      "      copying spacy\\lang\\eu\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\eu\n",
      "      copying spacy\\lang\\eu\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\eu\n",
      "      copying spacy\\lang\\eu\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\eu\n",
      "      copying spacy\\lang\\eu\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\eu\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\generate_verbs_exc.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      copying spacy\\lang\\fa\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fa\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      copying spacy\\lang\\fi\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fi\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\fo\n",
      "      copying spacy\\lang\\fo\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fo\n",
      "      copying spacy\\lang\\fo\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fo\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\_tokenizer_exceptions_list.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      copying spacy\\lang\\fr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\fr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ga\n",
      "      copying spacy\\lang\\ga\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ga\n",
      "      copying spacy\\lang\\ga\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ga\n",
      "      copying spacy\\lang\\ga\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ga\n",
      "      copying spacy\\lang\\ga\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ga\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\gd\n",
      "      copying spacy\\lang\\gd\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\gd\n",
      "      copying spacy\\lang\\gd\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\gd\n",
      "      copying spacy\\lang\\gd\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\gd\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      copying spacy\\lang\\grc\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      copying spacy\\lang\\grc\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      copying spacy\\lang\\grc\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      copying spacy\\lang\\grc\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      copying spacy\\lang\\grc\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      copying spacy\\lang\\grc\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\grc\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\gu\n",
      "      copying spacy\\lang\\gu\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\gu\n",
      "      copying spacy\\lang\\gu\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\gu\n",
      "      copying spacy\\lang\\gu\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\gu\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\he\n",
      "      copying spacy\\lang\\he\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\he\n",
      "      copying spacy\\lang\\he\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\he\n",
      "      copying spacy\\lang\\he\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\he\n",
      "      copying spacy\\lang\\he\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\he\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\hi\n",
      "      copying spacy\\lang\\hi\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hi\n",
      "      copying spacy\\lang\\hi\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hi\n",
      "      copying spacy\\lang\\hi\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hi\n",
      "      copying spacy\\lang\\hi\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hi\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\hr\n",
      "      copying spacy\\lang\\hr\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hr\n",
      "      copying spacy\\lang\\hr\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hr\n",
      "      copying spacy\\lang\\hr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\hsb\n",
      "      copying spacy\\lang\\hsb\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hsb\n",
      "      copying spacy\\lang\\hsb\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hsb\n",
      "      copying spacy\\lang\\hsb\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hsb\n",
      "      copying spacy\\lang\\hsb\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hsb\n",
      "      copying spacy\\lang\\hsb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hsb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\hu\n",
      "      copying spacy\\lang\\hu\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hu\n",
      "      copying spacy\\lang\\hu\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hu\n",
      "      copying spacy\\lang\\hu\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hu\n",
      "      copying spacy\\lang\\hu\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hu\n",
      "      copying spacy\\lang\\hu\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hu\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\hy\n",
      "      copying spacy\\lang\\hy\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hy\n",
      "      copying spacy\\lang\\hy\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hy\n",
      "      copying spacy\\lang\\hy\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hy\n",
      "      copying spacy\\lang\\hy\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hy\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\_tokenizer_exceptions_list.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      copying spacy\\lang\\id\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\id\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\is\n",
      "      copying spacy\\lang\\is\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\is\n",
      "      copying spacy\\lang\\is\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\is\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      copying spacy\\lang\\it\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\it\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\tag_bigram_map.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\tag_map.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\tag_orth_map.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      copying spacy\\lang\\ja\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ja\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\kmr\n",
      "      copying spacy\\lang\\kmr\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kmr\n",
      "      copying spacy\\lang\\kmr\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kmr\n",
      "      copying spacy\\lang\\kmr\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kmr\n",
      "      copying spacy\\lang\\kmr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kmr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\kn\n",
      "      copying spacy\\lang\\kn\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kn\n",
      "      copying spacy\\lang\\kn\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kn\n",
      "      copying spacy\\lang\\kn\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\kn\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      copying spacy\\lang\\ko\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      copying spacy\\lang\\ko\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      copying spacy\\lang\\ko\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      copying spacy\\lang\\ko\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      copying spacy\\lang\\ko\\tag_map.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      copying spacy\\lang\\ko\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ko\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      copying spacy\\lang\\ky\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      copying spacy\\lang\\ky\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      copying spacy\\lang\\ky\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      copying spacy\\lang\\ky\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      copying spacy\\lang\\ky\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      copying spacy\\lang\\ky\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ky\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      copying spacy\\lang\\la\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      copying spacy\\lang\\la\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      copying spacy\\lang\\la\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      copying spacy\\lang\\la\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      copying spacy\\lang\\la\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      copying spacy\\lang\\la\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\la\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      copying spacy\\lang\\lb\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      copying spacy\\lang\\lb\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      copying spacy\\lang\\lb\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      copying spacy\\lang\\lb\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      copying spacy\\lang\\lb\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      copying spacy\\lang\\lb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\lg\n",
      "      copying spacy\\lang\\lg\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lg\n",
      "      copying spacy\\lang\\lg\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lg\n",
      "      copying spacy\\lang\\lg\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lg\n",
      "      copying spacy\\lang\\lg\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lg\n",
      "      copying spacy\\lang\\lg\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lg\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\lij\n",
      "      copying spacy\\lang\\lij\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lij\n",
      "      copying spacy\\lang\\lij\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lij\n",
      "      copying spacy\\lang\\lij\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lij\n",
      "      copying spacy\\lang\\lij\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lij\n",
      "      copying spacy\\lang\\lij\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lij\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      copying spacy\\lang\\lt\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      copying spacy\\lang\\lt\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      copying spacy\\lang\\lt\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      copying spacy\\lang\\lt\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      copying spacy\\lang\\lt\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      copying spacy\\lang\\lt\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lt\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\lv\n",
      "      copying spacy\\lang\\lv\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lv\n",
      "      copying spacy\\lang\\lv\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\lv\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\mk\n",
      "      copying spacy\\lang\\mk\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mk\n",
      "      copying spacy\\lang\\mk\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mk\n",
      "      copying spacy\\lang\\mk\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mk\n",
      "      copying spacy\\lang\\mk\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mk\n",
      "      copying spacy\\lang\\mk\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mk\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ml\n",
      "      copying spacy\\lang\\ml\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ml\n",
      "      copying spacy\\lang\\ml\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ml\n",
      "      copying spacy\\lang\\ml\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ml\n",
      "      copying spacy\\lang\\ml\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ml\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\mr\n",
      "      copying spacy\\lang\\mr\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mr\n",
      "      copying spacy\\lang\\mr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\mr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\_tokenizer_exceptions_list.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      copying spacy\\lang\\ms\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ms\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      copying spacy\\lang\\nb\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      copying spacy\\lang\\nb\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      copying spacy\\lang\\nb\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      copying spacy\\lang\\nb\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      copying spacy\\lang\\nb\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      copying spacy\\lang\\nb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ne\n",
      "      copying spacy\\lang\\ne\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ne\n",
      "      copying spacy\\lang\\ne\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ne\n",
      "      copying spacy\\lang\\ne\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ne\n",
      "      copying spacy\\lang\\ne\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ne\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      copying spacy\\lang\\nl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\nn\n",
      "      copying spacy\\lang\\nn\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nn\n",
      "      copying spacy\\lang\\nn\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nn\n",
      "      copying spacy\\lang\\nn\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nn\n",
      "      copying spacy\\lang\\nn\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\nn\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      copying spacy\\lang\\pl\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      copying spacy\\lang\\pl\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      copying spacy\\lang\\pl\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      copying spacy\\lang\\pl\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      copying spacy\\lang\\pl\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      copying spacy\\lang\\pl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      copying spacy\\lang\\pt\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\pt\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      copying spacy\\lang\\ro\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      copying spacy\\lang\\ro\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      copying spacy\\lang\\ro\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      copying spacy\\lang\\ro\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      copying spacy\\lang\\ro\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      copying spacy\\lang\\ro\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ro\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      copying spacy\\lang\\ru\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      copying spacy\\lang\\ru\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      copying spacy\\lang\\ru\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      copying spacy\\lang\\ru\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      copying spacy\\lang\\ru\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      copying spacy\\lang\\ru\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ru\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\sa\n",
      "      copying spacy\\lang\\sa\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sa\n",
      "      copying spacy\\lang\\sa\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sa\n",
      "      copying spacy\\lang\\sa\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sa\n",
      "      copying spacy\\lang\\sa\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sa\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\si\n",
      "      copying spacy\\lang\\si\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\si\n",
      "      copying spacy\\lang\\si\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\si\n",
      "      copying spacy\\lang\\si\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\si\n",
      "      copying spacy\\lang\\si\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\si\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\sk\n",
      "      copying spacy\\lang\\sk\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sk\n",
      "      copying spacy\\lang\\sk\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sk\n",
      "      copying spacy\\lang\\sk\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sk\n",
      "      copying spacy\\lang\\sk\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sk\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      copying spacy\\lang\\sl\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      copying spacy\\lang\\sl\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      copying spacy\\lang\\sl\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      copying spacy\\lang\\sl\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      copying spacy\\lang\\sl\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      copying spacy\\lang\\sl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\sq\n",
      "      copying spacy\\lang\\sq\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sq\n",
      "      copying spacy\\lang\\sq\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sq\n",
      "      copying spacy\\lang\\sq\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sq\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\lang\\sr\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\lang\\sr\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\lang\\sr\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\lang\\sr\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\lang\\sr\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\lang\\sr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      copying spacy\\lang\\sv\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sv\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ta\n",
      "      copying spacy\\lang\\ta\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ta\n",
      "      copying spacy\\lang\\ta\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ta\n",
      "      copying spacy\\lang\\ta\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ta\n",
      "      copying spacy\\lang\\ta\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ta\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\te\n",
      "      copying spacy\\lang\\te\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\te\n",
      "      copying spacy\\lang\\te\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\te\n",
      "      copying spacy\\lang\\te\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\te\n",
      "      copying spacy\\lang\\te\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\te\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\th\n",
      "      copying spacy\\lang\\th\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\th\n",
      "      copying spacy\\lang\\th\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\th\n",
      "      copying spacy\\lang\\th\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\th\n",
      "      copying spacy\\lang\\th\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\th\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      copying spacy\\lang\\ti\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      copying spacy\\lang\\ti\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      copying spacy\\lang\\ti\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      copying spacy\\lang\\ti\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      copying spacy\\lang\\ti\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      copying spacy\\lang\\ti\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ti\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\tl\n",
      "      copying spacy\\lang\\tl\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tl\n",
      "      copying spacy\\lang\\tl\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tl\n",
      "      copying spacy\\lang\\tl\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tl\n",
      "      copying spacy\\lang\\tl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\tn\n",
      "      copying spacy\\lang\\tn\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tn\n",
      "      copying spacy\\lang\\tn\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tn\n",
      "      copying spacy\\lang\\tn\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tn\n",
      "      copying spacy\\lang\\tn\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tn\n",
      "      copying spacy\\lang\\tn\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tn\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      copying spacy\\lang\\tr\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      copying spacy\\lang\\tr\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      copying spacy\\lang\\tr\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      copying spacy\\lang\\tr\\syntax_iterators.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      copying spacy\\lang\\tr\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      copying spacy\\lang\\tr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      copying spacy\\lang\\tt\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      copying spacy\\lang\\tt\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      copying spacy\\lang\\tt\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      copying spacy\\lang\\tt\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      copying spacy\\lang\\tt\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      copying spacy\\lang\\tt\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\tt\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      copying spacy\\lang\\uk\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      copying spacy\\lang\\uk\\lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      copying spacy\\lang\\uk\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      copying spacy\\lang\\uk\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      copying spacy\\lang\\uk\\tokenizer_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      copying spacy\\lang\\uk\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\uk\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\ur\n",
      "      copying spacy\\lang\\ur\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ur\n",
      "      copying spacy\\lang\\ur\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ur\n",
      "      copying spacy\\lang\\ur\\punctuation.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ur\n",
      "      copying spacy\\lang\\ur\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ur\n",
      "      copying spacy\\lang\\ur\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\ur\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\vi\n",
      "      copying spacy\\lang\\vi\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\vi\n",
      "      copying spacy\\lang\\vi\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\vi\n",
      "      copying spacy\\lang\\vi\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\vi\n",
      "      copying spacy\\lang\\vi\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\vi\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\xx\n",
      "      copying spacy\\lang\\xx\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\xx\n",
      "      copying spacy\\lang\\xx\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\xx\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\yo\n",
      "      copying spacy\\lang\\yo\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\yo\n",
      "      copying spacy\\lang\\yo\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\yo\n",
      "      copying spacy\\lang\\yo\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\yo\n",
      "      copying spacy\\lang\\yo\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\yo\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\lang\\zh\n",
      "      copying spacy\\lang\\zh\\examples.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\zh\n",
      "      copying spacy\\lang\\zh\\lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\zh\n",
      "      copying spacy\\lang\\zh\\stop_words.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\zh\n",
      "      copying spacy\\lang\\zh\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\zh\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\entity_linker.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\multi_task.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\parser.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\spancat.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\span_finder.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\tagger.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\textcat.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\tok2vec.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      copying spacy\\ml\\models\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\ml\\models\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\legacy\n",
      "      copying spacy\\pipeline\\legacy\\entity_linker.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\legacy\n",
      "      copying spacy\\pipeline\\legacy\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\legacy\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_edit_tree_internals\n",
      "      copying spacy\\pipeline\\_edit_tree_internals\\schemas.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_edit_tree_internals\n",
      "      copying spacy\\pipeline\\_edit_tree_internals\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_edit_tree_internals\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_add_entities.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_array.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_creation.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_doc_api.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_graph.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_json_doc_conversion.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_morphanalysis.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_pickle_doc.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_retokenize_merge.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_retokenize_split.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_span.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_span_group.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_token_api.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\test_underscore.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      copying spacy\\tests\\doc\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\doc\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\n",
      "      copying spacy\\tests\\lang\\test_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\n",
      "      copying spacy\\tests\\lang\\test_initialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\n",
      "      copying spacy\\tests\\lang\\test_lemmatizers.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\n",
      "      copying spacy\\tests\\lang\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\test_dependency_matcher.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\test_levenshtein.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\test_matcher_api.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\test_matcher_logic.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\test_pattern_validation.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\test_phrase_matcher.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      copying spacy\\tests\\matcher\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\matcher\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\morphology\n",
      "      copying spacy\\tests\\morphology\\test_morph_converters.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\morphology\n",
      "      copying spacy\\tests\\morphology\\test_morph_features.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\morphology\n",
      "      copying spacy\\tests\\morphology\\test_morph_pickle.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\morphology\n",
      "      copying spacy\\tests\\morphology\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\morphology\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\package\n",
      "      copying spacy\\tests\\package\\test_requirements.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\package\n",
      "      copying spacy\\tests\\package\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\package\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_add_label.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_arc_eager_oracle.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_ner.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_neural_parser.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_nn_beam.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_nonproj.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_parse.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_parse_navigate.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_preset_sbd.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_space_attachment.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\test_state.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      copying spacy\\tests\\parser\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\parser\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_analysis.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_annotates_on_update.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_attributeruler.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_edit_tree_lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_entity_linker.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_entity_ruler.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_functions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_initialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_models.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_morphologizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_pipe_factories.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_pipe_methods.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_sentencizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_senter.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_spancat.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_span_finder.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_span_ruler.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_tagger.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_textcat.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\test_tok2vec.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      copying spacy\\tests\\pipeline\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\pipeline\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_resource_warning.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_config.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_doc.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_docbin.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_extension_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_kb.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_language.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_pipeline.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_span_groups.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\test_serialize_vocab_strings.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      copying spacy\\tests\\serialize\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\serialize\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\test_explain.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\test_naughty_strings.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\test_urls.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\test_whitespace.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      copying spacy\\tests\\tokenizer\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_augmenters.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_corpus.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_logger.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_new_example.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_pretraining.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_readers.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_rehearse.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\test_training.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      copying spacy\\tests\\training\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\training\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_lexeme.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_lookups.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_memory_zone.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_similarity.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_stringstore.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_vectors.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\test_vocab_api.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      copying spacy\\tests\\vocab_vectors\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\vocab_vectors\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\af\n",
      "      copying spacy\\tests\\lang\\af\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\af\n",
      "      copying spacy\\tests\\lang\\af\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\af\n",
      "      copying spacy\\tests\\lang\\af\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\af\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\am\n",
      "      copying spacy\\tests\\lang\\am\\test_exception.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\am\n",
      "      copying spacy\\tests\\lang\\am\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\am\n",
      "      copying spacy\\tests\\lang\\am\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\am\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ar\n",
      "      copying spacy\\tests\\lang\\ar\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ar\n",
      "      copying spacy\\tests\\lang\\ar\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ar\n",
      "      copying spacy\\tests\\lang\\ar\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ar\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\bn\n",
      "      copying spacy\\tests\\lang\\bn\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\bn\n",
      "      copying spacy\\tests\\lang\\bn\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\bn\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\bo\n",
      "      copying spacy\\tests\\lang\\bo\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\bo\n",
      "      copying spacy\\tests\\lang\\bo\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\bo\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ca\n",
      "      copying spacy\\tests\\lang\\ca\\test_exception.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ca\n",
      "      copying spacy\\tests\\lang\\ca\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ca\n",
      "      copying spacy\\tests\\lang\\ca\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ca\n",
      "      copying spacy\\tests\\lang\\ca\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ca\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\cs\n",
      "      copying spacy\\tests\\lang\\cs\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\cs\n",
      "      copying spacy\\tests\\lang\\cs\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\cs\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\da\n",
      "      copying spacy\\tests\\lang\\da\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\da\n",
      "      copying spacy\\tests\\lang\\da\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\da\n",
      "      copying spacy\\tests\\lang\\da\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\da\n",
      "      copying spacy\\tests\\lang\\da\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\da\n",
      "      copying spacy\\tests\\lang\\da\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\da\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      copying spacy\\tests\\lang\\de\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      copying spacy\\tests\\lang\\de\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      copying spacy\\tests\\lang\\de\\test_parser.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      copying spacy\\tests\\lang\\de\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      copying spacy\\tests\\lang\\de\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      copying spacy\\tests\\lang\\de\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\de\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\dsb\n",
      "      copying spacy\\tests\\lang\\dsb\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\dsb\n",
      "      copying spacy\\tests\\lang\\dsb\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\dsb\n",
      "      copying spacy\\tests\\lang\\dsb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\dsb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\el\n",
      "      copying spacy\\tests\\lang\\el\\test_exception.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\el\n",
      "      copying spacy\\tests\\lang\\el\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\el\n",
      "      copying spacy\\tests\\lang\\el\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\el\n",
      "      copying spacy\\tests\\lang\\el\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\el\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_customized_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_indices.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_parser.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_punct.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_sbd.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      copying spacy\\tests\\lang\\en\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\en\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\es\n",
      "      copying spacy\\tests\\lang\\es\\test_exception.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\es\n",
      "      copying spacy\\tests\\lang\\es\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\es\n",
      "      copying spacy\\tests\\lang\\es\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\es\n",
      "      copying spacy\\tests\\lang\\es\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\es\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\et\n",
      "      copying spacy\\tests\\lang\\et\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\et\n",
      "      copying spacy\\tests\\lang\\et\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\et\n",
      "      copying spacy\\tests\\lang\\et\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\et\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\eu\n",
      "      copying spacy\\tests\\lang\\eu\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\eu\n",
      "      copying spacy\\tests\\lang\\eu\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\eu\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fa\n",
      "      copying spacy\\tests\\lang\\fa\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fa\n",
      "      copying spacy\\tests\\lang\\fa\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fa\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fi\n",
      "      copying spacy\\tests\\lang\\fi\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fi\n",
      "      copying spacy\\tests\\lang\\fi\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fi\n",
      "      copying spacy\\tests\\lang\\fi\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fi\n",
      "      copying spacy\\tests\\lang\\fi\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fi\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fo\n",
      "      copying spacy\\tests\\lang\\fo\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fo\n",
      "      copying spacy\\tests\\lang\\fo\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fo\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fr\n",
      "      copying spacy\\tests\\lang\\fr\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fr\n",
      "      copying spacy\\tests\\lang\\fr\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fr\n",
      "      copying spacy\\tests\\lang\\fr\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fr\n",
      "      copying spacy\\tests\\lang\\fr\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fr\n",
      "      copying spacy\\tests\\lang\\fr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\fr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ga\n",
      "      copying spacy\\tests\\lang\\ga\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ga\n",
      "      copying spacy\\tests\\lang\\ga\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ga\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\grc\n",
      "      copying spacy\\tests\\lang\\grc\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\grc\n",
      "      copying spacy\\tests\\lang\\grc\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\grc\n",
      "      copying spacy\\tests\\lang\\grc\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\grc\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\gu\n",
      "      copying spacy\\tests\\lang\\gu\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\gu\n",
      "      copying spacy\\tests\\lang\\gu\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\gu\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\he\n",
      "      copying spacy\\tests\\lang\\he\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\he\n",
      "      copying spacy\\tests\\lang\\he\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\he\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hi\n",
      "      copying spacy\\tests\\lang\\hi\\test_lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hi\n",
      "      copying spacy\\tests\\lang\\hi\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hi\n",
      "      copying spacy\\tests\\lang\\hi\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hi\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hr\n",
      "      copying spacy\\tests\\lang\\hr\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hr\n",
      "      copying spacy\\tests\\lang\\hr\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hr\n",
      "      copying spacy\\tests\\lang\\hr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hsb\n",
      "      copying spacy\\tests\\lang\\hsb\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hsb\n",
      "      copying spacy\\tests\\lang\\hsb\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hsb\n",
      "      copying spacy\\tests\\lang\\hsb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hsb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hu\n",
      "      copying spacy\\tests\\lang\\hu\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hu\n",
      "      copying spacy\\tests\\lang\\hu\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hu\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hy\n",
      "      copying spacy\\tests\\lang\\hy\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hy\n",
      "      copying spacy\\tests\\lang\\hy\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hy\n",
      "      copying spacy\\tests\\lang\\hy\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\hy\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\id\n",
      "      copying spacy\\tests\\lang\\id\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\id\n",
      "      copying spacy\\tests\\lang\\id\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\id\n",
      "      copying spacy\\tests\\lang\\id\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\id\n",
      "      copying spacy\\tests\\lang\\id\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\id\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\is\n",
      "      copying spacy\\tests\\lang\\is\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\is\n",
      "      copying spacy\\tests\\lang\\is\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\is\n",
      "      copying spacy\\tests\\lang\\is\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\is\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\it\n",
      "      copying spacy\\tests\\lang\\it\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\it\n",
      "      copying spacy\\tests\\lang\\it\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\it\n",
      "      copying spacy\\tests\\lang\\it\\test_stopwords.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\it\n",
      "      copying spacy\\tests\\lang\\it\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\it\n",
      "      copying spacy\\tests\\lang\\it\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\it\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ja\n",
      "      copying spacy\\tests\\lang\\ja\\test_lemmatization.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ja\n",
      "      copying spacy\\tests\\lang\\ja\\test_morphologizer_factory.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ja\n",
      "      copying spacy\\tests\\lang\\ja\\test_serialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ja\n",
      "      copying spacy\\tests\\lang\\ja\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ja\n",
      "      copying spacy\\tests\\lang\\ja\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ja\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\kmr\n",
      "      copying spacy\\tests\\lang\\kmr\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\kmr\n",
      "      copying spacy\\tests\\lang\\kmr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\kmr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ko\n",
      "      copying spacy\\tests\\lang\\ko\\test_lemmatization.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ko\n",
      "      copying spacy\\tests\\lang\\ko\\test_serialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ko\n",
      "      copying spacy\\tests\\lang\\ko\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ko\n",
      "      copying spacy\\tests\\lang\\ko\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ko\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ky\n",
      "      copying spacy\\tests\\lang\\ky\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ky\n",
      "      copying spacy\\tests\\lang\\ky\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ky\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\la\n",
      "      copying spacy\\tests\\lang\\la\\test_exception.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\la\n",
      "      copying spacy\\tests\\lang\\la\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\la\n",
      "      copying spacy\\tests\\lang\\la\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\la\n",
      "      copying spacy\\tests\\lang\\la\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\la\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lb\n",
      "      copying spacy\\tests\\lang\\lb\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lb\n",
      "      copying spacy\\tests\\lang\\lb\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lb\n",
      "      copying spacy\\tests\\lang\\lb\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lb\n",
      "      copying spacy\\tests\\lang\\lb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lg\n",
      "      copying spacy\\tests\\lang\\lg\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lg\n",
      "      copying spacy\\tests\\lang\\lg\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lg\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lt\n",
      "      copying spacy\\tests\\lang\\lt\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lt\n",
      "      copying spacy\\tests\\lang\\lt\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lt\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lv\n",
      "      copying spacy\\tests\\lang\\lv\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lv\n",
      "      copying spacy\\tests\\lang\\lv\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lv\n",
      "      copying spacy\\tests\\lang\\lv\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\lv\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\mk\n",
      "      copying spacy\\tests\\lang\\mk\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\mk\n",
      "      copying spacy\\tests\\lang\\mk\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\mk\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ml\n",
      "      copying spacy\\tests\\lang\\ml\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ml\n",
      "      copying spacy\\tests\\lang\\ml\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ml\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ms\n",
      "      copying spacy\\tests\\lang\\ms\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ms\n",
      "      copying spacy\\tests\\lang\\ms\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ms\n",
      "      copying spacy\\tests\\lang\\ms\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ms\n",
      "      copying spacy\\tests\\lang\\ms\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ms\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nb\n",
      "      copying spacy\\tests\\lang\\nb\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nb\n",
      "      copying spacy\\tests\\lang\\nb\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nb\n",
      "      copying spacy\\tests\\lang\\nb\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nb\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ne\n",
      "      copying spacy\\tests\\lang\\ne\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ne\n",
      "      copying spacy\\tests\\lang\\ne\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ne\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nl\n",
      "      copying spacy\\tests\\lang\\nl\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nl\n",
      "      copying spacy\\tests\\lang\\nl\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nl\n",
      "      copying spacy\\tests\\lang\\nl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nn\n",
      "      copying spacy\\tests\\lang\\nn\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nn\n",
      "      copying spacy\\tests\\lang\\nn\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\nn\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pl\n",
      "      copying spacy\\tests\\lang\\pl\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pl\n",
      "      copying spacy\\tests\\lang\\pl\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pl\n",
      "      copying spacy\\tests\\lang\\pl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pt\n",
      "      copying spacy\\tests\\lang\\pt\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pt\n",
      "      copying spacy\\tests\\lang\\pt\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pt\n",
      "      copying spacy\\tests\\lang\\pt\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\pt\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ro\n",
      "      copying spacy\\tests\\lang\\ro\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ro\n",
      "      copying spacy\\tests\\lang\\ro\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ro\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ru\n",
      "      copying spacy\\tests\\lang\\ru\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ru\n",
      "      copying spacy\\tests\\lang\\ru\\test_lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ru\n",
      "      copying spacy\\tests\\lang\\ru\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ru\n",
      "      copying spacy\\tests\\lang\\ru\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ru\n",
      "      copying spacy\\tests\\lang\\ru\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ru\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sa\n",
      "      copying spacy\\tests\\lang\\sa\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sa\n",
      "      copying spacy\\tests\\lang\\sa\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sa\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sk\n",
      "      copying spacy\\tests\\lang\\sk\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sk\n",
      "      copying spacy\\tests\\lang\\sk\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sk\n",
      "      copying spacy\\tests\\lang\\sk\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sk\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sl\n",
      "      copying spacy\\tests\\lang\\sl\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sl\n",
      "      copying spacy\\tests\\lang\\sl\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sl\n",
      "      copying spacy\\tests\\lang\\sl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sq\n",
      "      copying spacy\\tests\\lang\\sq\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sq\n",
      "      copying spacy\\tests\\lang\\sq\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sq\n",
      "      copying spacy\\tests\\lang\\sq\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sq\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sr\n",
      "      copying spacy\\tests\\lang\\sr\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sr\n",
      "      copying spacy\\tests\\lang\\sr\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sr\n",
      "      copying spacy\\tests\\lang\\sr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\test_exceptions.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\test_lex_attrs.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      copying spacy\\tests\\lang\\sv\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\sv\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ta\n",
      "      copying spacy\\tests\\lang\\ta\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ta\n",
      "      copying spacy\\tests\\lang\\ta\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ta\n",
      "      copying spacy\\tests\\lang\\ta\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ta\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\th\n",
      "      copying spacy\\tests\\lang\\th\\test_serialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\th\n",
      "      copying spacy\\tests\\lang\\th\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\th\n",
      "      copying spacy\\tests\\lang\\th\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\th\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ti\n",
      "      copying spacy\\tests\\lang\\ti\\test_exception.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ti\n",
      "      copying spacy\\tests\\lang\\ti\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ti\n",
      "      copying spacy\\tests\\lang\\ti\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ti\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tl\n",
      "      copying spacy\\tests\\lang\\tl\\test_indices.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tl\n",
      "      copying spacy\\tests\\lang\\tl\\test_punct.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tl\n",
      "      copying spacy\\tests\\lang\\tl\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tl\n",
      "      copying spacy\\tests\\lang\\tl\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tl\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tr\n",
      "      copying spacy\\tests\\lang\\tr\\test_noun_chunks.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tr\n",
      "      copying spacy\\tests\\lang\\tr\\test_parser.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tr\n",
      "      copying spacy\\tests\\lang\\tr\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tr\n",
      "      copying spacy\\tests\\lang\\tr\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tr\n",
      "      copying spacy\\tests\\lang\\tr\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tr\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tt\n",
      "      copying spacy\\tests\\lang\\tt\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tt\n",
      "      copying spacy\\tests\\lang\\tt\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\tt\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\uk\n",
      "      copying spacy\\tests\\lang\\uk\\test_lemmatizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\uk\n",
      "      copying spacy\\tests\\lang\\uk\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\uk\n",
      "      copying spacy\\tests\\lang\\uk\\test_tokenizer_exc.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\uk\n",
      "      copying spacy\\tests\\lang\\uk\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\uk\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ur\n",
      "      copying spacy\\tests\\lang\\ur\\test_prefix_suffix_infix.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ur\n",
      "      copying spacy\\tests\\lang\\ur\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ur\n",
      "      copying spacy\\tests\\lang\\ur\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\ur\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\vi\n",
      "      copying spacy\\tests\\lang\\vi\\test_serialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\vi\n",
      "      copying spacy\\tests\\lang\\vi\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\vi\n",
      "      copying spacy\\tests\\lang\\vi\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\vi\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\xx\n",
      "      copying spacy\\tests\\lang\\xx\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\xx\n",
      "      copying spacy\\tests\\lang\\xx\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\xx\n",
      "      copying spacy\\tests\\lang\\xx\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\xx\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\yo\n",
      "      copying spacy\\tests\\lang\\yo\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\yo\n",
      "      copying spacy\\tests\\lang\\yo\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\yo\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\zh\n",
      "      copying spacy\\tests\\lang\\zh\\test_serialize.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\zh\n",
      "      copying spacy\\tests\\lang\\zh\\test_text.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\zh\n",
      "      copying spacy\\tests\\lang\\zh\\test_tokenizer.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\zh\n",
      "      copying spacy\\tests\\lang\\zh\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\lang\\zh\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\training\\converters\n",
      "      copying spacy\\training\\converters\\conllu_to_docs.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\\converters\n",
      "      copying spacy\\training\\converters\\conll_ner_to_docs.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\\converters\n",
      "      copying spacy\\training\\converters\\iob_to_docs.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\\converters\n",
      "      copying spacy\\training\\converters\\json_to_docs.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\\converters\n",
      "      copying spacy\\training\\converters\\__init__.py -> build\\lib.win-amd64-cpython-313\\spacy\\training\\converters\n",
      "      running egg_info\n",
      "      writing spacy.egg-info\\PKG-INFO\n",
      "      writing dependency_links to spacy.egg-info\\dependency_links.txt\n",
      "      writing entry points to spacy.egg-info\\entry_points.txt\n",
      "      writing requirements to spacy.egg-info\\requires.txt\n",
      "      writing top-level names to spacy.egg-info\\top_level.txt\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      reading manifest file 'spacy.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no previously-included files matching '*.cpp' found under directory 'spacy'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'spacy.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.kb' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.kb' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.kb' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.kb' to be distributed and are\n",
      "              already explicitly excluding 'spacy.kb' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.matcher' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.matcher' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.matcher' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.matcher' to be distributed and are\n",
      "              already explicitly excluding 'spacy.matcher' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.ml' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.ml' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.ml' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.ml' to be distributed and are\n",
      "              already explicitly excluding 'spacy.ml' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.pipeline' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.pipeline' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.pipeline' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.pipeline' to be distributed and are\n",
      "              already explicitly excluding 'spacy.pipeline' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.pipeline._edit_tree_internals' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.pipeline._edit_tree_internals' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.pipeline._edit_tree_internals' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.pipeline._edit_tree_internals' to be distributed and are\n",
      "              already explicitly excluding 'spacy.pipeline._edit_tree_internals' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.pipeline._parser_internals' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.pipeline._parser_internals' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.pipeline._parser_internals' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.pipeline._parser_internals' to be distributed and are\n",
      "              already explicitly excluding 'spacy.pipeline._parser_internals' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.tokens' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.tokens' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.tokens' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.tokens' to be distributed and are\n",
      "              already explicitly excluding 'spacy.tokens' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.training' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.training' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.training' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.training' to be distributed and are\n",
      "              already explicitly excluding 'spacy.training' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'spacy.cli.templates' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'spacy.cli.templates' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'spacy.cli.templates' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'spacy.cli.templates' to be distributed and are\n",
      "              already explicitly excluding 'spacy.cli.templates' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      copying spacy\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\attrs.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\attrs.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\attrs.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\default_config.cfg -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\default_config_pretraining.cfg -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\lexeme.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\lexeme.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\lexeme.pyi -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\lexeme.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\morphology.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\morphology.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\morphology.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\parts_of_speech.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\parts_of_speech.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\parts_of_speech.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\py.typed -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\strings.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\strings.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\strings.pyi -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\strings.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\structs.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\symbols.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\symbols.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\symbols.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\tokenizer.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\tokenizer.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\tokenizer.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\typedefs.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\typedefs.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\vectors.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\vectors.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\vocab.cpp -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\vocab.pxd -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\vocab.pyi -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\vocab.pyx -> build\\lib.win-amd64-cpython-313\\spacy\n",
      "      copying spacy\\kb\\candidate.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\kb.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\kb_in_memory.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\matcher\\dependencymatcher.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\levenshtein.c -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\matcher.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\phrasematcher.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\polyleven.c -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\ml\\parser_model.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\pipeline\\dep_parser.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\morphologizer.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\multitask.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\ner.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\pipe.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\sentencizer.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\senter.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\tagger.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\trainable_pipe.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\transition_parser.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\_edit_tree_internals\\edit_trees.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_edit_tree_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\_beam_utils.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\_state.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\arc_eager.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\ner.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\nonproj.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\nonproj.hh -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\stateclass.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\transition_system.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\tokens\\_retokenize.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\doc.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\graph.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\morphanalysis.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span_group.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\token.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\training\\align.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\alignment_array.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\example.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\gold_io.cpp -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      creating build\\lib.win-amd64-cpython-313\\spacy\\cli\\templates\n",
      "      copying spacy\\cli\\templates\\quickstart_training.jinja -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\templates\n",
      "      copying spacy\\cli\\templates\\quickstart_training_recommendations.yml -> build\\lib.win-amd64-cpython-313\\spacy\\cli\\templates\n",
      "      copying spacy\\kb\\candidate.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\candidate.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\kb.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\kb.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\kb_in_memory.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\kb\\kb_in_memory.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\kb\n",
      "      copying spacy\\matcher\\dependencymatcher.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\dependencymatcher.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\levenshtein.c -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\levenshtein.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\matcher.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\matcher.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\matcher.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\phrasematcher.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\phrasematcher.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\matcher\\phrasematcher.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\matcher\n",
      "      copying spacy\\ml\\parser_model.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\ml\\parser_model.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\ml\n",
      "      copying spacy\\pipeline\\dep_parser.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\morphologizer.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\multitask.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\ner.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\pipe.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\pipe.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\pipe.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\sentencizer.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\senter.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\tagger.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\trainable_pipe.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\trainable_pipe.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\transition_parser.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\pipeline\\transition_parser.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\n",
      "      copying spacy\\tokens\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\_retokenize.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\_retokenize.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\doc.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\doc.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\doc.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\graph.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\graph.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\morphanalysis.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\morphanalysis.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\morphanalysis.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span_group.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span_group.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\span_group.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\token.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\token.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\tokens\\token.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\tokens\n",
      "      copying spacy\\training\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\align.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\alignment_array.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\alignment_array.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\example.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\example.pyi -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\example.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\training\\gold_io.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\training\n",
      "      copying spacy\\lang\\hr\\lemma_lookup_license.txt -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\hr\n",
      "      copying spacy\\lang\\sr\\lemma_lookup_licence.txt -> build\\lib.win-amd64-cpython-313\\spacy\\lang\\sr\n",
      "      copying spacy\\pipeline\\_edit_tree_internals\\edit_trees.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_edit_tree_internals\n",
      "      copying spacy\\pipeline\\_edit_tree_internals\\edit_trees.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_edit_tree_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\_beam_utils.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\_beam_utils.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\_state.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\_state.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\arc_eager.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\arc_eager.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\ner.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\ner.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\nonproj.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\nonproj.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\stateclass.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\stateclass.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\transition_system.pxd -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\pipeline\\_parser_internals\\transition_system.pyx -> build\\lib.win-amd64-cpython-313\\spacy\\pipeline\\_parser_internals\n",
      "      copying spacy\\tests\\package\\pyproject.toml -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\package\n",
      "      copying spacy\\tests\\package\\requirements.txt -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\package\n",
      "      copying spacy\\tests\\package\\setup.cfg -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\package\n",
      "      copying spacy\\tests\\tokenizer\\sun.txt -> build\\lib.win-amd64-cpython-313\\spacy\\tests\\tokenizer\n",
      "      running build_ext\n",
      "      building 'spacy.matcher.levenshtein' extension\n",
      "      creating build\\temp.win-amd64-cpython-313\\Release\\spacy\\matcher\n",
      "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ispacy/matcher -IC:\\Users\\fonta\\AppData\\Local\\Temp\\pip-build-env-fk8jc53x\\overlay\\Lib\\site-packages\\numpy\\_core\\include \"-IC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\" -Ic:\\Users\\fonta\\Desktop\\Uni\\Repo\\NLP\\env\\include \"-IC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\include\" \"-IC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\Include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.26100.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\cppwinrt\" /Tcspacy/matcher/levenshtein.c /Fobuild\\temp.win-amd64-cpython-313\\Release\\spacy\\matcher\\levenshtein.obj /Ox /EHsc\n",
      "      levenshtein.c\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\spacy\\matcher\\polyleven.c(90): warning C4244: '=': conversion from 'int64_t' to 'int', possible loss of data\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\spacy\\matcher\\polyleven.c(137): warning C4244: 'function': conversion from 'int64_t' to 'int', possible loss of data\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\spacy\\matcher\\polyleven.c(139): warning C4244: '=': conversion from 'int64_t' to 'int', possible loss of data\n",
      "      C:\\Users\\fonta\\AppData\\Local\\Temp\\pip-install-v8mr89pi\\spacy_cdfab37a2a5747c8b06937e82d9728f7\\spacy\\matcher\\polyleven.c(267): warning C4244: 'function': conversion from 'int64_t' to 'int', possible loss of data\n",
      "      spacy/matcher/levenshtein.c(855): warning C4996: 'Py_UNICODE': deprecated in 3.13\n",
      "      spacy/matcher/levenshtein.c(856): warning C4996: 'Py_UNICODE': deprecated in 3.13\n",
      "      spacy/matcher/levenshtein.c(4514): error C2198: 'int _PyLong_AsByteArray(PyLongObject *,unsigned char *,size_t,int,int,int)': too few arguments for call\n",
      "      spacy/matcher/levenshtein.c(4786): error C2198: 'int _PyLong_AsByteArray(PyLongObject *,unsigned char *,size_t,int,int,int)': too few arguments for call\n",
      "      spacy/matcher/levenshtein.c(4982): error C2198: 'int _PyLong_AsByteArray(PyLongObject *,unsigned char *,size_t,int,int,int)': too few arguments for call\n",
      "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.43.34808\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for spaCy\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (spaCy)\n",
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%pip install spaCy\n",
    "# You need to download a specific model for each language\n",
    "# Each language has two models, one for efficiency and one for accuracy. https://spacy.io/usage/models\n",
    "%python -m spacy download en_core_web_sm # efficent model for English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eboUh4S-lXDL"
   },
   "source": [
    "# spaCy tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQFXKw6Yl5yb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOOjE-sMlgKR"
   },
   "source": [
    "*Notice that the installation doesn’t automatically download models. We need to do that ourselves. (python -m spacy download en_core_web_sm)*\n",
    "\n",
    "Hello World in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9402,
     "status": "ok",
     "timestamp": 1744726869565,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "v6qfXBODpGvF",
    "outputId": "5f2da567-82a2-4473-b879-730934bbf135"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      2\u001b[39m nlp = spacy.load(\u001b[33m'\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# load the language model\u001b[39;00m\n\u001b[32m      3\u001b[39m doc = nlp(\u001b[33m'\u001b[39m\u001b[33mHello World!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') # load the language model\n",
    "doc = nlp('Hello World!') #we can pass a string to the model and it will return a Doc object\n",
    "for token in doc: # the Doc object is iterable and we can iterate over it to get the tokens\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtf0Np7Ypntm"
   },
   "source": [
    "spaCy preserves this “link” between the word and its place in the raw text. Here’s how to get the exact index of a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1744726869591,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "RfkVc7TKpoeu",
    "outputId": "ef787c41-ba43-46a4-d2d5-4dd111ca62d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello  0\n",
      "World  6\n",
      "!  11\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text + ' ', token.idx) # the idx attribute gives us the index of the token in the original string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Qa9B12LuUnT"
   },
   "source": [
    "The **Token** class exposes a lot of word-level attributes. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1744726869629,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "fxK2cH9ruV48",
    "outputId": "ca21d5b4-93d0-4b20-b648-7bbbbc3bea9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next\t0\tnext\tFalse\tFalse\tXxxx\tADJ\tJJ\n",
      "week\t5\tweek\tFalse\tFalse\txxxx\tNOUN\tNN\n",
      "I\t10\tI\tFalse\tFalse\tX\tPRON\tPRP\n",
      "'ll\t11\twill\tFalse\tFalse\t'xx\tAUX\tMD\n",
      "be\t15\tbe\tFalse\tFalse\txx\tAUX\tVB\n",
      "in\t18\tin\tFalse\tFalse\txx\tADP\tIN\n",
      "Rome\t21\tRome\tFalse\tFalse\tXxxx\tPROPN\tNNP\n",
      ".\t25\t.\tTrue\tFalse\t.\tPUNCT\t.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Rome.\")\n",
    "for token in doc:\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
    "        token.text,\n",
    "        token.idx,\n",
    "        token.lemma_,\n",
    "        token.is_punct,\n",
    "        token.is_space,\n",
    "        token.shape_,\n",
    "        token.pos_,\n",
    "        token.tag_\n",
    "    ))\n",
    "\n",
    "    #for each token, we print the text, index, lemma, punctuation status, space status, shape, part of speech and tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKw3AR3Iunjb"
   },
   "source": [
    "## Sentence detection\n",
    "Here’s how to achieve one of the most common NLP tasks with spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1744726869671,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "N7AK_uofuobf",
    "outputId": "0e859169-1cf8-4a72-927c-2d63316af467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are apples.\n",
      "These are oranges.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"These are apples. These are oranges.\")\n",
    "\n",
    "for sent in doc.sents:  # the Doc object has a sents attribute which is a generator that yields sentences\n",
    "    # we can iterate over the sentences in the Doc object\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr5GaivKuxEt"
   },
   "source": [
    "## Part Of Speech Tagging\n",
    "PoS-tagging of a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1744726869779,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "0SPCdMJhuxpI",
    "outputId": "cb80aed5-3171-4b36-ac73-989711689de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Next', 'ADJ'), ('week', 'NOUN'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('in', 'ADP'), ('Madrid', 'PROPN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "print([(token.text, token.pos_) for token in doc]) # we can use list comprehension to get the text and part of speech of each token in the Doc object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIwj7h7gu0gs"
   },
   "source": [
    "## Named Entity Recognition\n",
    "Doing NER with spaCy is super easy and the pretrained model performs pretty well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1744726869795,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "MkbmiqJLu2i8",
    "outputId": "f1ffb7de-24a5-4dfd-9678-285642952eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next week DATE\n",
      "Madrid GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "for ent in doc.ents: # the Doc object has an ents attribute which is a list of named entities in the Doc object\n",
    "    # we can iterate over the named entities in the Doc object\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn5sD_9FvEwo"
   },
   "source": [
    "You can also view the IOB style tagging of the sentence like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1744726869813,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "NC4ytRWQvFDH",
    "outputId": "a0daeced-52c5-47ee-bf36-0ba5cb5ad5ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Next', 'JJ', 'B-DATE'), ('week', 'NN', 'I-DATE'), ('I', 'PRP', 'O'), (\"'ll\", 'MD', 'O'), ('be', 'VB', 'O'), ('in', 'IN', 'O'), ('Madrid', 'NNP', 'B-GPE'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "iob_tagged = [\n",
    "    (\n",
    "        token.text,\n",
    "        token.tag_,\n",
    "        \"{0}-{1}\".format(token.ent_iob_, token.ent_type_) if token.ent_iob_ != 'O' else token.ent_iob_\n",
    "    ) for token in doc\n",
    "    #insted of using doc.ents, we can use the ent_iob_ and ent_type_ attributes of each token to get the IOB tags\n",
    "    # the ent_iob_ attribute gives us the IOB tag of the token and the ent_type_ attribute gives us the type of the entity\n",
    "]\n",
    "print(iob_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14YgcbyvvYaG"
   },
   "source": [
    "The spaCy NER also has a healthy variety of entities. You can view the full list here: https://spacy.io/usage/linguistic-features#entity-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1744726869910,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "DZgmrVtAvXde",
    "outputId": "4c38ba66-3947-4e9f-88f1-cfb4bb393e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CARDINAL\n",
      "9 a.m. TIME\n",
      "30% PERCENT\n",
      "just 2 days DATE\n",
      "WSJ ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_) # we can use the label_ attribute of the named entity to get the type of the entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a1O_1KWvkuN"
   },
   "source": [
    "Let’s use displaCy to view a beautiful visualization of the Named Entity annotated sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1744726869948,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "X2s_Om6fvmmt",
    "outputId": "d597f2c4-2041-4480-d64b-6974ab169c6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    9 a.m.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " because the stock went up \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    30%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    just 2 days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " according to the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WSJ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp('I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
    "displacy.render(doc, style='ent', jupyter=True) # we can use the displacy module to visualize the named entities in the Doc object\n",
    "# displacy is a module in spaCy that allows us to visualize the named entities in the Doc object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4gc6A62vvXJ"
   },
   "source": [
    "## Chunking\n",
    "spaCy automatically detects noun-phrases as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1744726869954,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "ZUDhlXVDvz1j",
    "outputId": "8b21b452-fc1a-49e4-a5fc-8f622460368b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall Street Journal NP Journal\n",
      "an interesting piece NP piece\n",
      "crypto currencies NP currencies\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.label_, chunk.root.text)\n",
    "\n",
    "#A chunk is a contiguous span of tokens that form a single noun phrase.\n",
    "# The noun_chunks attribute of the Doc object gives us a generator that yields the noun chunks in the Doc object.\n",
    "# We can iterate over the noun chunks in the Doc object and print the text, label and root of each chunk.\n",
    "# The label attribute gives us the label of the chunk and the root attribute gives us the root token of the chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvlq8h5WwKH4"
   },
   "source": [
    "Notice how the chunker also computes the root of the phrase, the main word of the phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O1Uqf3DwBNF"
   },
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "Let’s see the dependency parser in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1744726869973,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "h2OZOPInwLWF",
    "outputId": "d3a46781-7ecd-4bd4-e7a3-d1fa70c628fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall/NNP <--compound-- Street/NNP\n",
      "Street/NNP <--compound-- Journal/NNP\n",
      "Journal/NNP <--nsubj-- published/VBD\n",
      "just/RB <--advmod-- published/VBD\n",
      "published/VBD <--ROOT-- published/VBD\n",
      "an/DT <--det-- piece/NN\n",
      "interesting/JJ <--amod-- piece/NN\n",
      "piece/NN <--dobj-- published/VBD\n",
      "on/IN <--prep-- piece/NN\n",
      "crypto/JJ <--compound-- currencies/NNS\n",
      "currencies/NNS <--pobj-- on/IN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n",
    "        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))\n",
    "\n",
    "#dependency parsing is the process of analyzing the grammatical structure of a sentence and establishing relationships between words.    \n",
    "# The dep_ attribute gives us the dependency relation of the token and the head attribute gives us the head token of the token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4-eoMzRwac4"
   },
   "source": [
    "If this doesn’t help visualizing the dependency tree, displaCy comes in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1744726870000,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "uZKy_d_Nwa3P",
    "outputId": "00712a18-54b8-4331-bc82-1974b495196e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"20823862fc65414bac5244f51c08d853-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Wall</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Street</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Journal</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">just</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">published</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">an</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">interesting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">piece</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">crypto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">currencies</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 405.0,47.0 405.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,139.0 L512,127.0 528,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-6\" stroke-width=\"2px\" d=\"M430,137.0 C430,2.0 680.0,2.0 680.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M680.0,139.0 L688.0,127.0 672.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-20823862fc65414bac5244f51c08d853-0-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-20823862fc65414bac5244f51c08d853-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
    "\n",
    "# we can use the displacy module to visualize the dependency parse of the Doc object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnRYTSeWMGbT"
   },
   "source": [
    "# A simple case study\n",
    "Now, we download a text file and process its content using spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1744726871185,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "tsEgMdwAMBZ7",
    "outputId": "08f12d64-7819-46e6-ca23-ff5ba864a01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-15 14:21:09--  https://www.gutenberg.org/ebooks/2701.txt.utf-8\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: http://www.gutenberg.org/cache/epub/2701/pg2701.txt [following]\n",
      "--2025-04-15 14:21:10--  http://www.gutenberg.org/cache/epub/2701/pg2701.txt\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.gutenberg.org/cache/epub/2701/pg2701.txt [following]\n",
      "--2025-04-15 14:21:10--  https://www.gutenberg.org/cache/epub/2701/pg2701.txt\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1276288 (1.2M) [text/plain]\n",
      "Saving to: ‘2701.txt.utf-8.1’\n",
      "\n",
      "2701.txt.utf-8.1    100%[===================>]   1.22M  3.75MB/s    in 0.3s    \n",
      "\n",
      "2025-04-15 14:21:10 (3.75 MB/s) - ‘2701.txt.utf-8.1’ saved [1276288/1276288]\n",
      "\n",
      "﻿The Project Gutenberg eBook of Moby Dick; Or, The Whale\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.gutenberg.org/ebooks/2701.txt.utf-8\n",
    "!head -n 5 2701.txt.utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nsf7F8f5M6i-"
   },
   "source": [
    "Remove the header and footer from the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UC7qsOlWM5nM"
   },
   "outputs": [],
   "source": [
    "file = open('2701.txt.utf-8','r')\n",
    "outFile = open('moby_dick.txt','w')\n",
    "copyToFile = False\n",
    "for l in file:\n",
    "  if l.startswith('*** END OF THE PROJECT GUTENBERG EBOOK'):\n",
    "    copyToFile = False\n",
    "  if copyToFile:\n",
    "    outFile.write(' ')\n",
    "    outFile.write(l)\n",
    "    if len(l)==0:\n",
    "      outFile.write('\\n')\n",
    "  if l.startswith('*** START OF THE PROJECT GUTENBERG EBOOK'):\n",
    "    copyToFile = True\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1744726871398,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "Y8BO4QO4OAah",
    "outputId": "8fac1961-03e3-4c57-8ced-d6fa7eaa85e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " MOBY-DICK;\n",
      " \n",
      " or, THE WHALE.\n",
      " \n",
      " By Herman Melville\n",
      " \n",
      " \n",
      " \n",
      " CONTENTS\n",
      " \n",
      " ETYMOLOGY.\n",
      " \n",
      " EXTRACTS (Supplied by a Sub-Sub-Librarian).\n",
      " \n",
      " CHAPTER 1. Loomings.\n",
      " \n",
      " CHAPTER 2. The Carpet-Bag.\n",
      " \n",
      " CHAPTER 3. The Spouter-Inn.\n",
      " \n",
      " CHAPTER 4. The Counterpane.\n",
      " \n",
      " CHAPTER 5. Breakfast.\n",
      " \n",
      " CHAPTER 6. The Street.\n",
      " \n",
      " CHAPTER 7. The Chapel.\n",
      " \n",
      " CHAPTER 8. The Pulpit.\n",
      " \n",
      " CHAPTER 9. The Sermon.\n",
      " \n",
      " CHAPTER 10. A Bosom Friend.\n",
      " \n",
      " CHAPTER 11. Nightgown.\n",
      " \n",
      " CHAPTER 12. Biographical.\n",
      " \n",
      " CHAPTER 13. Wheelbarrow.\n",
      " \n",
      " CHAPTER 14. Nantucket.\n",
      " \n",
      " CHAPTER 15. Chowder.\n",
      " \n",
      " CHAPTER 16. The Ship.\n",
      " \n",
      " CHAPTER 17. The Ramadan.\n",
      " \n",
      " CHAPTER 18. His Mark.\n",
      " \n",
      " CHAPTER 19. The Prophet.\n",
      " \n",
      " CHAPTER 20. All Astir.\n",
      " \n",
      " CHAPTER 21. Going Aboard.\n",
      " \n",
      " CHAPTER 22. Merry Christmas.\n",
      " \n",
      " CHAPTER 23. The Lee Shore.\n",
      " \n",
      " CHAPTER 24. The Advocate.\n",
      " \n",
      " CHAPTER 25. Postscript.\n",
      " \n",
      " CHAPTER 26. Knights and Squires.\n",
      " \n",
      " CHAPTER 27. Knights and Squires.\n",
      " \n",
      " CHAPTER 28. Ahab.\n",
      " \n",
      " CHAPTER 29. Enter Ahab; to Him, Stubb.\n",
      " \n",
      " CHAPTER 30. The Pipe.\n",
      " \n",
      " CHAPTER 31. Queen Mab.\n",
      " \n",
      " CHAPTER 32. Cetology.\n",
      " \n",
      " CHAPTER 33. The Specksnyder.\n",
      " \n",
      " CHAPTER 34. The Cabin-Table.\n",
      " \n",
      " CHAPTER 35. The Mast-Head.\n",
      " \n",
      " CHAPTER 36. The Quarter-Deck.\n",
      " \n",
      " CHAPTER 37. Sunset.\n",
      " \n",
      " CHAPTER 38. Dusk.\n",
      " \n",
      " CHAPTER 39. First Night-Watch.\n",
      " \n",
      " CHAPTER 40. Midnight, Forecastle.\n",
      " \n",
      " CHAPTER 41. Moby Dick.\n",
      " \n",
      " CHAPTER 42. The Whiteness of the Whale.\n",
      " \n",
      " CHAPTER 43. Hark!\n",
      " \n",
      " CHAPTER 44. The Chart.\n",
      " \n",
      " CHAPTER 45. The Affidavit.\n",
      " \n",
      " CHAPTER 46. Surmises.\n",
      " \n",
      " CHAPTER 47. The Mat-Maker.\n",
      " \n",
      " CHAPTER 48. The First Lowering.\n",
      " \n",
      " CHAPTER 49. The Hyena.\n",
      " \n",
      " CHAPTER 50. Ahab’s Boat and Crew. Fedallah.\n",
      " \n",
      " CHAPTER 51. The Spirit-Spout.\n",
      " \n",
      " CHAPTER 52. The Albatross.\n",
      " \n",
      " CHAPTER 53. The Gam.\n",
      " \n",
      " CHAPTER 54. The Town-Ho’s Story.\n",
      " \n",
      " CHAPTER 55. Of the Monstrous Pictures of Whales.\n",
      " \n",
      " CHAPTER 56. Of the Less Erroneous Pictures of Whales, and the True\n",
      " Pictures of Whaling Scenes.\n",
      " \n",
      " CHAPTER 57. Of Whales in Paint; in Teeth; in Wood; in Sheet-Iron; in\n",
      " Stone; in Mountains; in Stars.\n",
      " \n",
      " CHAPTER 58. Brit.\n",
      " \n",
      " CHAPTER 59. Squid.\n",
      " \n",
      " CHAPTER 60. The Line.\n",
      " \n",
      " CHAPTER 61. Stubb Kills a Whale.\n",
      " \n",
      " CHAPTER 62. The Dart.\n",
      " \n",
      " CHAPTER 63. The Crotch.\n",
      " \n",
      " CHAPTER 64. Stubb’s Supper.\n",
      " \n",
      " CHAPTER 65. The Whale as a Dish.\n",
      " \n",
      " CHAPTER 66. The Shark Massacre.\n",
      " \n",
      " CHAPTER 67. Cutting In.\n",
      " \n",
      " CHAPTER 68. The Blanket.\n",
      " \n",
      " CHAPTER 69. The Funeral.\n",
      " \n",
      " CHAPTER 70. The Sphynx.\n",
      " \n",
      " CHAPTER 71. The Jeroboam’s Story.\n",
      " \n",
      " CHAPTER 72. The Monkey-Rope.\n",
      " \n",
      " CHAPTER 73. Stubb and Flask kill a Right Whale; and Then Have a Talk\n",
      " over Him.\n",
      " \n",
      " CHAPTER 74. The Sperm Whale’s Head—Contrasted View.\n",
      " \n",
      " CHAPTER 75. The Right Whale’s Head—Contrasted View.\n",
      " \n",
      " CHAPTER 76. The Battering-Ram.\n",
      " \n",
      " CHAPTER 77. The Great Heidelburgh Tun.\n",
      " \n",
      " CHAPTER 78. Cistern and Buckets.\n",
      " \n",
      " CHAPTER 79. The Prairie.\n",
      " \n",
      " CHAPTER 80. The Nut.\n",
      " \n",
      " CHAPTER 81. The Pequod Meets The Virgin.\n",
      " \n",
      " CHAPTER 82. The Honor and Glory of Whaling.\n",
      " \n",
      " CHAPTER 83. Jonah Historically Regarded.\n",
      " \n",
      " CHAPTER 84. Pitchpoling.\n",
      " \n",
      " CHAPTER 85. The Fountain.\n",
      " \n",
      " CHAPTER 86. The Tail.\n",
      " \n",
      " CHAPTER 87. The Grand Armada.\n",
      " \n",
      " CHAPTER 88. Schools and Schoolmasters.\n",
      " \n",
      " CHAPTER 89. Fast-Fish and Loose-Fish.\n",
      " \n",
      " CHAPTER 90. Heads or Tails.\n",
      " \n",
      " CHAPTER 91. The Pequod Meets The Rose-Bud.\n",
      " \n",
      " CHAPTER 92. Ambergris.\n",
      " \n",
      " CHAPTER 93. The Castaway.\n",
      " \n",
      " CHAPTER 94. A Squeeze of the Hand.\n",
      " \n",
      " CHAPTER 95. The Cassock.\n",
      " \n",
      " CHAPTER 96. The Try-Works.\n",
      " \n",
      " CHAPTER 97. The Lamp.\n",
      " \n",
      " CHAPTER 98. Stowing Down and Clearing Up.\n",
      " \n",
      " CHAPTER 99. The Doubloon.\n",
      " \n",
      " CHAPTER 100. Leg and Arm.\n",
      " \n",
      " CHAPTER 101. The Decanter.\n",
      " \n",
      " CHAPTER 102. A Bower in the Arsacides.\n",
      " \n",
      " CHAPTER 103. Measurement of The Whale’s Skeleton.\n",
      " \n",
      " CHAPTER 104. The Fossil Whale.\n",
      " \n",
      " CHAPTER 105. Does the Whale’s Magnitude Diminish?—Will He Perish?\n",
      " \n",
      " CHAPTER 106. Ahab’s Leg.\n",
      " \n",
      " CHAPTER 107. The Carpenter.\n",
      " \n",
      " CHAPTER 108. Ahab and the Carpenter.\n",
      " \n",
      " CHAPTER 109. Ahab and Starbuck in the Cabin.\n",
      " \n",
      " CHAPTER 110. Queequeg in His Coffin.\n",
      " \n",
      " CHAPTER 111. The Pacific.\n",
      " \n",
      " CHAPTER 112. The Blacksmith.\n",
      " \n",
      " CHAPTER 113. The Forge.\n",
      " \n",
      " CHAPTER 114. The Gilder.\n",
      " \n",
      " CHAPTER 115. The Pequod Meets The Bachelor.\n",
      " \n",
      " CHAPTER 116. The Dying Whale.\n",
      " \n",
      " CHAPTER 117. The Whale Watch.\n",
      " \n",
      " CHAPTER 118. The Quadrant.\n",
      " \n",
      " CHAPTER 119. The Candles.\n",
      " \n",
      " CHAPTER 120. The Deck Towards the End of the First Night Watch.\n",
      " \n",
      " CHAPTER 121. Midnight.—The Forecastle Bulwarks.\n",
      " \n",
      " CHAPTER 122. Midnight Aloft.—Thunder and Lightning.\n",
      " \n",
      " CHAPTER 123. The Musket.\n",
      " \n",
      " CHAPTER 124. The Needle.\n",
      " \n",
      " CHAPTER 125. The Log and Line.\n",
      " \n",
      " CHAPTER 126. The Life-Buoy.\n",
      " \n",
      " CHAPTER 127. The Deck.\n",
      " \n",
      " CHAPTER 128. The Pequod Meets The Rachel.\n",
      " \n",
      " CHAPTER 129. The Cabin.\n",
      " \n",
      " CHAPTER 130. The Hat.\n",
      " \n",
      " CHAPTER 131. The Pequod Meets The Delight.\n",
      " \n",
      " CHAPTER 132. The Symphony.\n",
      " \n",
      " CHAPTER 133. The Chase—First Day.\n",
      " \n",
      " CHAPTER 134. The Chase—Second Day.\n",
      " \n",
      " CHAPTER 135. The Chase.—Third Day.\n",
      " \n",
      " Epilogue\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Original Transcriber’s Notes:\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " This text is a combination of etexts, one from the now-defunct ERIS\n",
      " project at Virginia Tech and one from Project Gutenberg’s archives. The\n",
      " proofreaders of this version are indebted to The University of Adelaide\n",
      " Library for preserving the Virginia Tech version. The resulting etext\n",
      " was compared with a public domain hard copy version of the text.\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   ETYMOLOGY.\n",
      " \n",
      " \n",
      "   (Supplied by a Late Consumptive Usher to a Grammar School.)\n",
      " \n",
      "   The pale Usher—threadbare in coat, heart, body, and brain; I see him\n",
      "   now. He was ever dusting his old lexicons and grammars, with a queer\n",
      "   handkerchief, mockingly embellished with all the gay flags of all the\n",
      "   known nations of the world. He loved to dust his old grammars; it\n",
      "   somehow mildly reminded him of his mortality.\n",
      " \n",
      "   “While you take in hand to school others, and to teach them by what\n",
      "   name a whale-fish is to be called in our tongue, leaving out, through\n",
      "   ignorance, the letter H, which almost alone maketh up the\n",
      "   signification of the word, you deliver that which is not true.”\n",
      "   —_Hackluyt._\n",
      " \n",
      "   “WHALE. * * * Sw. and Dan. _hval_. This animal is named from\n",
      "   roundness or rolling; for in Dan. _hvalt_ is arched or vaulted.”\n",
      "   —_Webster’s Dictionary._\n",
      " \n",
      "   “WHALE. * * * It is more immediately from the Dut. and Ger. _Wallen_;\n",
      "   A.S. _Walw-ian_, to roll, to wallow.” —_Richardson’s Dictionary._\n",
      " \n",
      " \n",
      "   חו,                 _Hebrew_.\n",
      "   ϰητος,              _Greek_.\n",
      "   CETUS,              _Latin_.\n",
      "   WHŒL,               _Anglo-Saxon_.\n",
      "   HVALT,              _Danish_.\n",
      "   WAL,                _Dutch_.\n",
      "   HWAL,               _Swedish_.\n",
      "   WHALE,              _Icelandic_.\n",
      "   WHALE,              _English_.\n",
      "   BALLENA,            _Spanish_.\n",
      "   PEKEE-NUEE-NUEE,    _Fegee_.\n",
      "   PEHEE-NUEE-NUEE,    _Erromangoan_.\n",
      " \n",
      " \n",
      " \n",
      "   EXTRACTS. (Supplied by a Sub-Sub-Librarian).\n",
      " \n",
      " \n",
      " \n",
      "   It will be seen that this mere painstaking burrower and grub-worm of\n",
      "   a poor devil of a Sub-Sub appears to have gone through the long\n",
      "   Vaticans and street-stalls of the earth, picking up whatever random\n",
      "   allusions to whales he could anyways find in any book whatsoever,\n",
      "   sacred or profane. Therefore you must not, in every case at least,\n",
      "   take the higgledy-piggledy whale statements, however authentic, in\n",
      "   these extracts, for veritable gospel cetology. Far from it. As\n",
      "   touching the ancient authors generally, as well as the poets here\n",
      "   appearing, these extracts are solely valuable or entertaining, as\n",
      "   affording a glancing bird’s eye view of what has been promiscuously\n",
      "   said, thought, fancied, and sung of Leviathan, by many nations and\n",
      "   generations, including our own.\n",
      " \n",
      "   So fare thee well, poor devil of a Sub-Sub, whose commentator I am.\n",
      "   Thou belongest to that hopeless, sallow tribe which no wine of this\n",
      "   world will ever warm; and for whom even Pale Sherry would be too\n",
      "   rosy-strong; but with whom one sometimes loves to sit, and feel\n",
      "   poor-devilish, too; and grow convivial upon tears; and say to them\n",
      "   bluntly, with full eyes and empty glasses, and in not altogether\n",
      "   unpleasant sadness—Give it up, Sub-Subs! For by how much the more\n",
      "   pains ye take to please the world, by so much the more shall ye for\n",
      "   ever go thankless! Would that I could clear out Hampton Court and the\n",
      "   Tuileries for ye! But gulp down your tears and hie aloft to the\n",
      "   royal-mast with your hearts; for your friends who have gone before\n",
      "   are clearing out the seven-storied heavens, and making refugees of\n",
      "   long-pampered Gabriel, Michael, and Raphael, against your coming.\n",
      "   Here ye strike but splintered hearts together—there, ye shall strike\n",
      "   unsplinterable glasses!\n",
      " \n",
      " EXTRACTS.\n",
      " \n",
      "   “And God created great whales.” —_Genesis_.\n",
      " \n",
      "   “Leviathan maketh a path to shine after him; One would think the deep\n",
      "   to be hoary.” —_Job_.\n",
      " \n",
      "   “Now the Lord had prepared a great fish to swallow up Jonah.”\n",
      "   —_Jonah_.\n",
      " \n",
      "   “There go the ships; there is that Leviathan whom thou hast made to\n",
      "   play therein.” —_Psalms_.\n",
      " \n",
      "   “In that day, the Lord with his sore, and great, and strong sword,\n",
      "   shall punish Leviathan the piercing serpent, even Leviathan that\n",
      "   crooked serpent; and he shall slay the dragon that is in the sea.”\n",
      "   —_Isaiah_.\n",
      " \n",
      "   “And what thing soever besides cometh within the chaos of this\n",
      "   monster’s mouth, be it beast, boat, or stone, down it goes all\n",
      "   incontinently that foul great swallow of his, and perisheth in the\n",
      "   bottomless gulf of his paunch.” —_Holland’s Plutarch’s Morals_.\n",
      " \n",
      "   “The Indian Sea breedeth the most and the biggest fishes that are:\n",
      "   among which the Whales and Whirlpooles called Balaene, take up as\n",
      "   much in length as four acres or arpens of land.” —_Holland’s Pliny_.\n",
      " \n",
      "   “Scarcely had we proceeded two days on the sea, when about sunrise a\n",
      "   great many Whales and other monsters of the sea, appeared. Among the\n",
      "   former, one was of a most monstrous size.... This came towards us,\n",
      "   open-mouthed, raising the waves on all sides, and beating the sea\n",
      "   before him into a foam.” —_Tooke’s Lucian_. “_The True History_.”\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   “He visited this country also with a view of catching horse-whales,\n",
      "   which had bones of very great value for their teeth, of which he\n",
      "   brought some to the king.... The best whales were catched in his own\n",
      "   country, of which some were forty-eight, some fifty yards long. He\n",
      "   said that he was one of six who had killed sixty in two days.”\n",
      "   —_Other or Other’s verbal narrative taken down from his mouth by King\n",
      "   Alfred, A.D._ 890.\n",
      " \n",
      "   “And whereas all the other things, whether beast or vessel, that\n",
      "   enter into the dreadful gulf of this monster’s (whale’s) mouth, are\n",
      "   immediately lost and swallowed up, the sea-gudgeon retires into it in\n",
      "   great security, and there sleeps.” —MONTAIGNE. —_Apology for Raimond\n",
      "   Sebond_.\n",
      " \n",
      "   “Let us fly, let us fly! Old Nick take me if it is not Leviathan\n",
      "   described by the noble prophet Moses in the life of patient Job.”\n",
      "   —_Rabelais_.\n",
      " \n",
      "   “This whale’s liver was two cartloads.” —_Stowe’s Annals_.\n",
      " \n",
      "   “The great Leviathan that maketh the seas to seethe like boiling\n",
      "   pan.” —_Lord Bacon’s Version of the Psalms_.\n",
      " \n",
      "   “Touching that monstrous bulk of the whale or ork we have received\n",
      "   nothing certain. They grow exceeding fat, insomuch that an incredible\n",
      "   quantity of oil will be extracted out of one whale.” —_Ibid_.\n",
      "   “_History of Life and Death_.”\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   “The sovereignest thing on earth is parmacetti for an inward bruise.”\n",
      "   —_King Henry_.\n",
      " \n",
      "   “Very like a whale.” —_Hamlet_.\n",
      " \n",
      " \n",
      "   “Which to secure, no skill of leach’s art Mote him availle, but to\n",
      "   returne againe To his wound’s worker, that with lowly dart, Dinting\n",
      "   his breast, had bred his restless paine, Like as the wounded whale to\n",
      "   shore flies thro’ the maine.” —_The Fairie Queen_.\n",
      " \n",
      " \n",
      " \n",
      "   “Immense as whales, the motion of whose vast bodies can in a peaceful\n",
      "   calm trouble the ocean till it boil.” —_Sir William Davenant. Preface\n",
      "   to Gondibert_.\n",
      " \n",
      "   “What spermacetti is, men might justly doubt, since the learned\n",
      "   Hosmannus in his work of thirty years, saith plainly, _Nescio quid\n",
      "   sit_.” —_Sir T. Browne. Of Sperma Ceti and the Sperma Ceti Whale.\n",
      "   Vide his V. E._\n",
      " \n",
      " \n",
      "   “Like Spencer’s Talus with his modern flail He threatens ruin with\n",
      "   his ponderous tail. ... Their fixed jav’lins in his side he wears,\n",
      "   And on his back a grove of pikes appears.” —_Waller’s Battle of the\n",
      "   Summer Islands_.\n",
      " \n",
      " \n",
      " \n",
      "   “By art is created that great Leviathan, called a Commonwealth or\n",
      "   State—(in Latin, Civitas) which is but an artificial man.” —_Opening\n",
      "   sentence of Hobbes’s Leviathan_.\n",
      " \n",
      "   “Silly Mansoul swallowed it without chewing, as if it had been a\n",
      "   sprat in the mouth of a whale.” —_Pilgrim’s Progress_.\n",
      " \n",
      " \n",
      "   “That sea beast Leviathan, which God of all his works Created hugest\n",
      "   that swim the ocean stream.” —_Paradise Lost_.\n",
      " \n",
      "   —“There Leviathan, Hugest of living creatures, in the deep Stretched\n",
      "   like a promontory sleeps or swims, And seems a moving land; and at\n",
      "   his gills Draws in, and at his breath spouts out a sea.” —_Ibid_.\n",
      " \n",
      " \n",
      " \n",
      "   “The mighty whales which swim in a sea of water, and have a sea of\n"
     ]
    }
   ],
   "source": [
    "!head -n 500 moby_dick.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTjp2xpBX3KD"
   },
   "source": [
    "Count occurrences for each NOUN in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPKOrILsUYnj"
   },
   "outputs": [],
   "source": [
    "file = open('moby_dick.txt','r')\n",
    "text = \"\"\n",
    "nouns = {}\n",
    "for l in file:\n",
    "  l = l.strip()\n",
    "  if len(l)==0 and len(text)>0:\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "      if token.pos_=='NOUN':\n",
    "        if token.lemma_ in nouns:\n",
    "          nouns[token.lemma_] = nouns[token.lemma_] + 1\n",
    "        else:\n",
    "          nouns[token.lemma_] = 1\n",
    "    text = \"\"\n",
    "  elif len(l)>0:\n",
    "    text += \" \" + l\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1744726938248,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "mCuGsh2JZRwL",
    "outputId": "28a11e58-3d61-4ab5-b687-c14d6f00a8d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whale': 1121,\n",
       " 'man': 745,\n",
       " 'ship': 594,\n",
       " 'sea': 509,\n",
       " 'boat': 477,\n",
       " 'time': 438,\n",
       " 'head': 414,\n",
       " 'hand': 322,\n",
       " 'thing': 318,\n",
       " '_': 304,\n",
       " 'way': 287,\n",
       " 'water': 255,\n",
       " 'day': 253,\n",
       " 'eye': 242,\n",
       " 'side': 227,\n",
       " 'deck': 209,\n",
       " 'line': 192,\n",
       " 'part': 188,\n",
       " 'life': 182,\n",
       " 'world': 179,\n",
       " 'sort': 168,\n",
       " 'ye': 166,\n",
       " 'foot': 160,\n",
       " 'night': 158,\n",
       " 'fish': 155,\n",
       " 'crew': 154,\n",
       " 'air': 140,\n",
       " 'captain': 140,\n",
       " 'harpooneer': 130,\n",
       " 'place': 127,\n",
       " 'year': 121,\n",
       " 'arm': 121,\n",
       " 'body': 119,\n",
       " 'end': 117,\n",
       " 'heart': 117,\n",
       " 'moment': 117,\n",
       " 'mast': 116,\n",
       " 'sight': 116,\n",
       " 'mate': 115,\n",
       " 'whaleman': 113,\n",
       " 'leg': 110,\n",
       " 'voyage': 106,\n",
       " 'sperm': 106,\n",
       " 'sail': 105,\n",
       " 'soul': 104,\n",
       " 'one': 104,\n",
       " 'harpoon': 104,\n",
       " 'sailor': 103,\n",
       " 'face': 103,\n",
       " 'word': 102,\n",
       " 'iron': 101,\n",
       " 'sun': 101,\n",
       " 'sir': 100,\n",
       " 'thou': 100,\n",
       " 'bone': 98,\n",
       " 'case': 96,\n",
       " 'oil': 91,\n",
       " 'matter': 90,\n",
       " 'wind': 89,\n",
       " 'tail': 88,\n",
       " 'bow': 87,\n",
       " 'ocean': 85,\n",
       " 'boy': 83,\n",
       " 'length': 82,\n",
       " 'hour': 82,\n",
       " 'cabin': 82,\n",
       " 'land': 81,\n",
       " 'death': 81,\n",
       " 'vessel': 80,\n",
       " 'order': 80,\n",
       " 'name': 79,\n",
       " 'bed': 79,\n",
       " 'point': 78,\n",
       " 'creature': 76,\n",
       " 'reason': 75,\n",
       " 'fire': 74,\n",
       " 'work': 73,\n",
       " 'aye': 73,\n",
       " 'shark': 72,\n",
       " 'morning': 72,\n",
       " 'instant': 71,\n",
       " 'mouth': 70,\n",
       " 'jaw': 70,\n",
       " 'rope': 69,\n",
       " 'board': 68,\n",
       " 'business': 68,\n",
       " 'devil': 66,\n",
       " 'lance': 66,\n",
       " 'light': 66,\n",
       " 'thought': 65,\n",
       " 'oar': 63,\n",
       " 'blood': 62,\n",
       " 'room': 62,\n",
       " 'whaling': 61,\n",
       " 'spout': 61,\n",
       " 'mind': 60,\n",
       " 'ground': 60,\n",
       " 'monster': 58,\n",
       " 'fishery': 58,\n",
       " 'interval': 57,\n",
       " 'gentleman': 57,\n",
       " 'wave': 56,\n",
       " 'fellow': 56,\n",
       " 'book': 55,\n",
       " 'tooth': 55,\n",
       " 'seaman': 55,\n",
       " 'story': 54,\n",
       " 'craft': 54,\n",
       " 'voice': 53,\n",
       " 'fact': 53,\n",
       " 'circumstance': 52,\n",
       " 'bottom': 52,\n",
       " 'hole': 52,\n",
       " 'chance': 51,\n",
       " 'savage': 51,\n",
       " 'door': 51,\n",
       " 'watch': 51,\n",
       " 'back': 49,\n",
       " 'house': 49,\n",
       " 'instance': 49,\n",
       " 'quarter': 49,\n",
       " 'pipe': 48,\n",
       " 'chase': 48,\n",
       " 'sign': 48,\n",
       " 'cry': 48,\n",
       " 'object': 47,\n",
       " 'plank': 47,\n",
       " 'n’t': 47,\n",
       " 'hold': 47,\n",
       " 'view': 46,\n",
       " 'coffin': 46,\n",
       " 'king': 46,\n",
       " 'round': 46,\n",
       " 'mark': 46,\n",
       " 'earth': 45,\n",
       " 'coast': 45,\n",
       " 'look': 45,\n",
       " 'rest': 45,\n",
       " 'carpenter': 45,\n",
       " 'course': 45,\n",
       " 'sky': 45,\n",
       " 'brain': 44,\n",
       " 'yard': 44,\n",
       " 'art': 44,\n",
       " 'hunter': 44,\n",
       " 'wood': 43,\n",
       " 'wake': 43,\n",
       " 'ivory': 43,\n",
       " 'top': 43,\n",
       " 'power': 43,\n",
       " 'brow': 43,\n",
       " 'friend': 42,\n",
       " 'stern': 42,\n",
       " 'form': 42,\n",
       " 'mariner': 42,\n",
       " 'people': 42,\n",
       " 'hat': 42,\n",
       " 'purpose': 42,\n",
       " 'fluke': 42,\n",
       " 'terror': 42,\n",
       " 'aspect': 42,\n",
       " 'surface': 42,\n",
       " 'distance': 41,\n",
       " 'jet': 41,\n",
       " 'table': 41,\n",
       " '’s': 41,\n",
       " '-': 40,\n",
       " 'sound': 40,\n",
       " 'knife': 40,\n",
       " 'other': 39,\n",
       " 'nature': 39,\n",
       " 'island': 39,\n",
       " 'storm': 39,\n",
       " 'idea': 39,\n",
       " 'inch': 39,\n",
       " 'fin': 39,\n",
       " 'horse': 38,\n",
       " 'manner': 38,\n",
       " 'home': 38,\n",
       " 'ear': 38,\n",
       " 'company': 38,\n",
       " 'stranger': 38,\n",
       " 'forehead': 37,\n",
       " 'skin': 37,\n",
       " 'scene': 37,\n",
       " 'skeleton': 37,\n",
       " 'pole': 37,\n",
       " 'child': 36,\n",
       " 'mile': 36,\n",
       " 'wonder': 36,\n",
       " 'leviathan': 36,\n",
       " 'weather': 36,\n",
       " 'question': 36,\n",
       " 'circle': 36,\n",
       " 'mass': 35,\n",
       " 'tree': 35,\n",
       " 'bulwark': 35,\n",
       " 'officer': 35,\n",
       " 'forecastle': 35,\n",
       " 'peril': 35,\n",
       " 'minute': 35,\n",
       " 'truth': 35,\n",
       " 'age': 35,\n",
       " 'nose': 35,\n",
       " 'hull': 35,\n",
       " 'hammer': 35,\n",
       " 'turn': 34,\n",
       " 'person': 34,\n",
       " 'half': 34,\n",
       " 'bit': 34,\n",
       " 'lad': 34,\n",
       " 'piece': 34,\n",
       " 'shipmate': 34,\n",
       " 'none': 34,\n",
       " 'mean': 34,\n",
       " 'whaler': 34,\n",
       " 'bulk': 33,\n",
       " 'fisherman': 33,\n",
       " 'passage': 33,\n",
       " 'snow': 33,\n",
       " 'wall': 33,\n",
       " 'hammock': 33,\n",
       " 'gold': 33,\n",
       " 'substance': 33,\n",
       " 'glance': 33,\n",
       " 'queer': 32,\n",
       " 'rib': 32,\n",
       " 'steel': 32,\n",
       " 'account': 32,\n",
       " 'port': 32,\n",
       " 'flame': 32,\n",
       " 'lamp': 32,\n",
       " 'woe': 32,\n",
       " 'degree': 31,\n",
       " 'chapter': 31,\n",
       " 'picture': 31,\n",
       " 'darkness': 31,\n",
       " 'hair': 31,\n",
       " 'number': 31,\n",
       " 'cask': 31,\n",
       " 'thee': 31,\n",
       " 'oarsman': 31,\n",
       " 'coat': 30,\n",
       " 'battle': 30,\n",
       " 'lightning': 30,\n",
       " 'gale': 30,\n",
       " 'act': 30,\n",
       " 'spring': 30,\n",
       " 'wife': 30,\n",
       " 'keel': 30,\n",
       " 'glass': 29,\n",
       " 'country': 29,\n",
       " 'motion': 29,\n",
       " 'shore': 29,\n",
       " 'god': 29,\n",
       " 'shadow': 29,\n",
       " 'chest': 29,\n",
       " 'skull': 29,\n",
       " 'rock': 28,\n",
       " 'rigging': 28,\n",
       " 'nigh': 28,\n",
       " 'pot': 28,\n",
       " 'lip': 28,\n",
       " 'latitude': 28,\n",
       " 'tackle': 28,\n",
       " 'gunwale': 28,\n",
       " 'supper': 27,\n",
       " 'bird': 27,\n",
       " 'fear': 27,\n",
       " 'compass': 27,\n",
       " 'ice': 27,\n",
       " 'jacket': 27,\n",
       " 'duty': 27,\n",
       " 'anchor': 27,\n",
       " 'rod': 27,\n",
       " 'elephant': 27,\n",
       " 'midnight': 26,\n",
       " 'self': 26,\n",
       " 'thunder': 26,\n",
       " 'smoke': 26,\n",
       " 'row': 26,\n",
       " 'spot': 26,\n",
       " 'landlord': 26,\n",
       " 'finger': 26,\n",
       " 'pilot': 26,\n",
       " 'command': 26,\n",
       " 'owner': 26,\n",
       " 'blubber': 26,\n",
       " 'tub': 26,\n",
       " 'sword': 25,\n",
       " 'specie': 25,\n",
       " 'pursuit': 25,\n",
       " 'war': 25,\n",
       " 'being': 25,\n",
       " 'figure': 25,\n",
       " 'event': 25,\n",
       " 'law': 25,\n",
       " 'helm': 25,\n",
       " 'level': 25,\n",
       " 'spade': 25,\n",
       " 'street': 24,\n",
       " 'history': 24,\n",
       " 'breath': 24,\n",
       " 'kind': 24,\n",
       " 'respect': 24,\n",
       " 'front': 24,\n",
       " 'town': 24,\n",
       " 'subject': 24,\n",
       " 'while': 24,\n",
       " 'hint': 24,\n",
       " 'direction': 24,\n",
       " 'calm': 24,\n",
       " 'doubloon': 24,\n",
       " 'shoulder': 23,\n",
       " 'play': 23,\n",
       " 'hill': 23,\n",
       " 'breeze': 23,\n",
       " 'honor': 23,\n",
       " 'use': 23,\n",
       " 'mine': 23,\n",
       " 'centre': 23,\n",
       " 'whole': 23,\n",
       " 'month': 23,\n",
       " 'flesh': 23,\n",
       " 'prow': 23,\n",
       " 'billow': 23,\n",
       " 'state': 23,\n",
       " 'chain': 23,\n",
       " 'strength': 23,\n",
       " 'season': 23,\n",
       " 'herd': 23,\n",
       " 'magnitude': 22,\n",
       " 'letter': 22,\n",
       " 'animal': 22,\n",
       " 'feeling': 22,\n",
       " 'isle': 22,\n",
       " 'term': 22,\n",
       " 'floor': 22,\n",
       " 'mother': 22,\n",
       " 'dog': 22,\n",
       " 'century': 22,\n",
       " 'son': 22,\n",
       " 'affair': 22,\n",
       " 'log': 22,\n",
       " 'scuttle': 22,\n",
       " 'windlass': 22,\n",
       " 'bucket': 21,\n",
       " 'stone': 21,\n",
       " 'sleep': 21,\n",
       " 'barrel': 21,\n",
       " 'right': 21,\n",
       " 'needle': 21,\n",
       " 'glory': 21,\n",
       " 'bag': 21,\n",
       " 'middle': 21,\n",
       " 'window': 21,\n",
       " 'box': 21,\n",
       " 'neck': 21,\n",
       " 'lady': 21,\n",
       " 'woman': 21,\n",
       " 'commander': 21,\n",
       " 'period': 21,\n",
       " 'example': 21,\n",
       " 'whiteness': 21,\n",
       " 'try': 21,\n",
       " 'living': 20,\n",
       " 'colour': 20,\n",
       " 'horn': 20,\n",
       " 'vicinity': 20,\n",
       " 'mountain': 20,\n",
       " 'spar': 20,\n",
       " 'merchant': 20,\n",
       " 'corner': 20,\n",
       " 'space': 20,\n",
       " 'cannibal': 20,\n",
       " 'coward': 20,\n",
       " 'game': 20,\n",
       " 'palm': 20,\n",
       " 'depth': 20,\n",
       " 'foe': 20,\n",
       " 'shape': 20,\n",
       " 'ghost': 20,\n",
       " 'dignity': 20,\n",
       " 'pump': 20,\n",
       " 'star': 19,\n",
       " 'flag': 19,\n",
       " 'foam': 19,\n",
       " 'love': 19,\n",
       " 'comrade': 19,\n",
       " 'interest': 19,\n",
       " 'ball': 19,\n",
       " 'out': 19,\n",
       " 'field': 19,\n",
       " 'trunk': 19,\n",
       " 'phantom': 19,\n",
       " 'difference': 19,\n",
       " 'hump': 19,\n",
       " 'rate': 19,\n",
       " 'height': 19,\n",
       " 'sake': 19,\n",
       " 'stuff': 19,\n",
       " 'silence': 19,\n",
       " 'father': 19,\n",
       " 'tide': 19,\n",
       " 'master': 19,\n",
       " 'aft': 19,\n",
       " 'spirit': 19,\n",
       " 'globe': 19,\n",
       " 'noon': 19,\n",
       " 'horizon': 19,\n",
       " 'flank': 19,\n",
       " 'school': 18,\n",
       " 'heaven': 18,\n",
       " 'stroke': 18,\n",
       " 'element': 18,\n",
       " 'shroud': 18,\n",
       " 'landsman': 18,\n",
       " 'bench': 18,\n",
       " 'virtue': 18,\n",
       " 'fowl': 18,\n",
       " 'nameless': 18,\n",
       " 'canoe': 18,\n",
       " 'pocket': 18,\n",
       " 'block': 18,\n",
       " 'spear': 18,\n",
       " 'evening': 18,\n",
       " 'hook': 18,\n",
       " 'peculiarity': 18,\n",
       " 'roll': 18,\n",
       " 'spite': 18,\n",
       " 'marble': 18,\n",
       " 'race': 18,\n",
       " 'advance': 18,\n",
       " 'ring': 18,\n",
       " 'spine': 18,\n",
       " 'beef': 18,\n",
       " 'usage': 18,\n",
       " 'blow': 18,\n",
       " 'candle': 17,\n",
       " 'nation': 17,\n",
       " 'pain': 17,\n",
       " 'dart': 17,\n",
       " 'weight': 17,\n",
       " 'weapon': 17,\n",
       " 'rear': 17,\n",
       " 'city': 17,\n",
       " 'lung': 17,\n",
       " 'horror': 17,\n",
       " 'conceit': 17,\n",
       " 'step': 17,\n",
       " 'pulpit': 17,\n",
       " 'seat': 17,\n",
       " 'tomahawk': 17,\n",
       " 'negro': 17,\n",
       " 'cloud': 17,\n",
       " 'e': 17,\n",
       " 'hue': 17,\n",
       " 'touch': 17,\n",
       " 'cause': 17,\n",
       " 'hatch': 17,\n",
       " 'base': 17,\n",
       " 'crown': 17,\n",
       " 'madness': 17,\n",
       " 'd’ye': 17,\n",
       " 'vapor': 17,\n",
       " 'lantern': 17,\n",
       " 'wreck': 17,\n",
       " 'buoy': 16,\n",
       " 'prophet': 16,\n",
       " 'wound': 16,\n",
       " 'belly': 16,\n",
       " 'joy': 16,\n",
       " 'bread': 16,\n",
       " 'paper': 16,\n",
       " 'wharf': 16,\n",
       " 'thousand': 16,\n",
       " 'knee': 16,\n",
       " 'meaning': 16,\n",
       " 'sense': 16,\n",
       " 'blade': 16,\n",
       " 'boot': 16,\n",
       " 'summer': 16,\n",
       " 'plenty': 16,\n",
       " 'opinion': 16,\n",
       " 'grass': 16,\n",
       " 'sheet': 16,\n",
       " 'steak': 16,\n",
       " 'pitch': 16,\n",
       " 'doubt': 16,\n",
       " 'cord': 16,\n",
       " 'heat': 16,\n",
       " 'dream': 16,\n",
       " 'shock': 16,\n",
       " 'hope': 16,\n",
       " 'feature': 16,\n",
       " 'rush': 16,\n",
       " 'fore': 16,\n",
       " 'barb': 16,\n",
       " 'start': 16,\n",
       " 'beach': 16,\n",
       " 'leak': 16,\n",
       " 'wing': 16,\n",
       " 'squall': 16,\n",
       " 'fool': 16,\n",
       " 'limb': 16,\n",
       " 'binnacle': 16,\n",
       " 'article': 15,\n",
       " 'shoal': 15,\n",
       " 'appearance': 15,\n",
       " 'church': 15,\n",
       " 'answer': 15,\n",
       " 'monkey': 15,\n",
       " 'dam': 15,\n",
       " 'effect': 15,\n",
       " 'dinner': 15,\n",
       " 'character': 15,\n",
       " 'glimpse': 15,\n",
       " 'memory': 15,\n",
       " 'swell': 15,\n",
       " 'will': 15,\n",
       " 'position': 15,\n",
       " 'influence': 15,\n",
       " 'bull': 15,\n",
       " 'impression': 15,\n",
       " 'experience': 15,\n",
       " 'volume': 15,\n",
       " 'hunt': 15,\n",
       " 'headsman': 15,\n",
       " 'mood': 15,\n",
       " 'corpse': 15,\n",
       " 'breakfast': 14,\n",
       " 'tongue': 14,\n",
       " 'size': 14,\n",
       " 'stream': 14,\n",
       " 'consideration': 14,\n",
       " 'pirate': 14,\n",
       " 'pair': 14,\n",
       " 'stage': 14,\n",
       " 'noise': 14,\n",
       " 'occasion': 14,\n",
       " 'week': 14,\n",
       " 'care': 14,\n",
       " 'family': 14,\n",
       " 'flood': 14,\n",
       " 'mystery': 14,\n",
       " 'cheek': 14,\n",
       " 'angel': 14,\n",
       " 'stock': 14,\n",
       " 'grave': 14,\n",
       " 'wrinkle': 14,\n",
       " 'plate': 14,\n",
       " 'shoe': 14,\n",
       " 'coin': 14,\n",
       " 'fathom': 14,\n",
       " 'luck': 14,\n",
       " 'food': 14,\n",
       " 'nail': 14,\n",
       " 'party': 14,\n",
       " 'stump': 14,\n",
       " 'coil': 14,\n",
       " 'astern': 14,\n",
       " 'spray': 14,\n",
       " 'bubble': 14,\n",
       " 'naturalist': 14,\n",
       " 'hearse': 14,\n",
       " 'ginger': 14,\n",
       " 'cutting': 14,\n",
       " 'content': 13,\n",
       " 'wine': 13,\n",
       " 'quantity': 13,\n",
       " 'prey': 13,\n",
       " 'reference': 13,\n",
       " 'brother': 13,\n",
       " 'principle': 13,\n",
       " 'score': 13,\n",
       " 'sand': 13,\n",
       " 'image': 13,\n",
       " 'salt': 13,\n",
       " 'cook': 13,\n",
       " 'slave': 13,\n",
       " 'fancy': 13,\n",
       " 'bar': 13,\n",
       " 'measure': 13,\n",
       " 'jack': 13,\n",
       " 'seal': 13,\n",
       " 'idol': 13,\n",
       " 'trowser': 13,\n",
       " 'canvas': 13,\n",
       " 'girl': 13,\n",
       " 'mist': 13,\n",
       " 'mankind': 13,\n",
       " 'secret': 13,\n",
       " 'ladder': 13,\n",
       " 'authority': 13,\n",
       " 'doom': 13,\n",
       " 'lesson': 13,\n",
       " 'hitherto': 13,\n",
       " 'conscience': 13,\n",
       " 'present': 13,\n",
       " 'strait': 13,\n",
       " 'fleet': 13,\n",
       " 'tiller': 13,\n",
       " 'force': 13,\n",
       " 'chart': 13,\n",
       " 'host': 13,\n",
       " 'canal': 13,\n",
       " 'vice': 13,\n",
       " 'allusion': 12,\n",
       " 'tribe': 12,\n",
       " 'narrative': 12,\n",
       " 'deal': 12,\n",
       " 'hoop': 12,\n",
       " 'dread': 12,\n",
       " 'money': 12,\n",
       " 'league': 12,\n",
       " 'lake': 12,\n",
       " 'drop': 12,\n",
       " 'fountain': 12,\n",
       " 'ashe': 12,\n",
       " 'coal': 12,\n",
       " 'oath': 12,\n",
       " 'winter': 12,\n",
       " 'blanket': 12,\n",
       " 'cup': 12,\n",
       " 'meat': 12,\n",
       " 'chap': 12,\n",
       " 'set': 12,\n",
       " 'contrast': 12,\n",
       " 'plan': 12,\n",
       " 'wrist': 12,\n",
       " 'stove': 12,\n",
       " 'morrow': 12,\n",
       " 'clothe': 12,\n",
       " 'smoking': 12,\n",
       " 'naught': 12,\n",
       " 'movement': 12,\n",
       " 'traveller': 12,\n",
       " 'bell': 12,\n",
       " 'milk': 12,\n",
       " 'porpoise': 12,\n",
       " 'countenance': 12,\n",
       " 'accident': 12,\n",
       " 'faith': 12,\n",
       " 'fate': 12,\n",
       " 'speed': 12,\n",
       " 'page': 12,\n",
       " 'murderer': 12,\n",
       " 'flight': 12,\n",
       " 'lock': 12,\n",
       " 'bowel': 12,\n",
       " 'fit': 12,\n",
       " 'commotion': 12,\n",
       " 'bolt': 12,\n",
       " 'quality': 12,\n",
       " 'fashion': 12,\n",
       " 'lay': 12,\n",
       " 'cap': 12,\n",
       " 'windward': 12,\n",
       " 'tower': 12,\n",
       " 'cruising': 12,\n",
       " 'hail': 12,\n",
       " 'perch': 12,\n",
       " 'nest': 12,\n",
       " 'symbol': 12,\n",
       " 'warp': 12,\n",
       " 'organ': 12,\n",
       " 'sunset': 11,\n",
       " 'talk': 11,\n",
       " 'ignorance': 11,\n",
       " 'boiling': 11,\n",
       " 'swimming': 11,\n",
       " 'baleen': 11,\n",
       " 'afternoon': 11,\n",
       " 'extremity': 11,\n",
       " 'hell': 11,\n",
       " 'possession': 11,\n",
       " 'might': 11,\n",
       " 'passenger': 11,\n",
       " 'key': 11,\n",
       " 'gloom': 11,\n",
       " 'service': 11,\n",
       " 'blackness': 11,\n",
       " 'shade': 11,\n",
       " 'news': 11,\n",
       " 'chair': 11,\n",
       " 'telling': 11,\n",
       " 'stair': 11,\n",
       " 'clam': 11,\n",
       " 'fight': 11,\n",
       " 'biscuit': 11,\n",
       " 'operation': 11,\n",
       " 'spell': 11,\n",
       " 'vengeance': 11,\n",
       " 'malice': 11,\n",
       " 'widow': 11,\n",
       " 'tone': 11,\n",
       " 'cable': 11,\n",
       " 'berth': 11,\n",
       " 'timber': 11,\n",
       " 'attitude': 11,\n",
       " 'black': 11,\n",
       " 'mortal': 11,\n",
       " 'puff': 11,\n",
       " 'waist': 11,\n",
       " 'need': 11,\n",
       " 'flash': 11,\n",
       " 'vocation': 11,\n",
       " 'blast': 11,\n",
       " 'expression': 11,\n",
       " 'consternation': 11,\n",
       " 'chowder': 11,\n",
       " 'harbor': 11,\n",
       " 'aught': 11,\n",
       " 'agent': 11,\n",
       " 'spectacle': 11,\n",
       " 'knowledge': 11,\n",
       " 'meeting': 11,\n",
       " 'thine': 11,\n",
       " 'sleeper': 11,\n",
       " 'musket': 11,\n",
       " 'discovery': 11,\n",
       " 'action': 11,\n",
       " 'tambourine': 11,\n",
       " 'emotion': 11,\n",
       " 'layer': 11,\n",
       " 'plain': 11,\n",
       " 'summit': 11,\n",
       " 'job': 11,\n",
       " 'contact': 11,\n",
       " 'priest': 11,\n",
       " 'tiger': 11,\n",
       " 'lid': 11,\n",
       " 'dish': 10,\n",
       " 'author': 10,\n",
       " 'path': 10,\n",
       " 'skill': 10,\n",
       " 'opening': 10,\n",
       " 'charge': 10,\n",
       " 'velocity': 10,\n",
       " 'whip': 10,\n",
       " 'curiosity': 10,\n",
       " 'wheel': 10,\n",
       " 'east': 10,\n",
       " 'valley': 10,\n",
       " 'pyramid': 10,\n",
       " 'tar': 10,\n",
       " 'awe': 10,\n",
       " 'contrary': 10,\n",
       " 'shirt': 10,\n",
       " 'frost': 10,\n",
       " 'chip': 10,\n",
       " 'midst': 10,\n",
       " 'knot': 10,\n",
       " 'handle': 10,\n",
       " 'sunrise': 10,\n",
       " 'angle': 10,\n",
       " 'bear': 10,\n",
       " 'yarn': 10,\n",
       " 'mat': 10,\n",
       " 'edge': 10,\n",
       " 'baby': 10,\n",
       " 'pagan': 10,\n",
       " 'strip': 10,\n",
       " 'laugh': 10,\n",
       " 'reflection': 10,\n",
       " 'taste': 10,\n",
       " 'spermaceti': 10,\n",
       " 'yesterday': 10,\n",
       " 'contrivance': 10,\n",
       " 'prayer': 10,\n",
       " 'delight': 10,\n",
       " 'truck': 10,\n",
       " 'gallant': 10,\n",
       " 'future': 10,\n",
       " 'heel': 10,\n",
       " 'strain': 10,\n",
       " 'prairie': 10,\n",
       " 'navy': 10,\n",
       " 'moon': 10,\n",
       " 'butter': 10,\n",
       " 'concern': 10,\n",
       " 'birth': 10,\n",
       " 'religion': 10,\n",
       " 'task': 10,\n",
       " 'gun': 10,\n",
       " 'humor': 10,\n",
       " 'quest': 10,\n",
       " 'seam': 10,\n",
       " 'band': 10,\n",
       " 'repose': 10,\n",
       " 'mainmast': 10,\n",
       " 'powder': 10,\n",
       " 'system': 10,\n",
       " 'brace': 10,\n",
       " 'vial': 10,\n",
       " 'fiend': 10,\n",
       " 'necessity': 10,\n",
       " 'rail': 10,\n",
       " 'SAILOR': 10,\n",
       " 'beginning': 10,\n",
       " 'sounding': 10,\n",
       " 'breadth': 10,\n",
       " 'engraving': 10,\n",
       " 'ton': 10,\n",
       " 'screw': 10,\n",
       " 'beast': 9,\n",
       " 'garden': 9,\n",
       " 'branch': 9,\n",
       " 'spire': 9,\n",
       " 'visit': 9,\n",
       " 'region': 9,\n",
       " 'butt': 9,\n",
       " 'capture': 9,\n",
       " 'assault': 9,\n",
       " 'tale': 9,\n",
       " 'crowd': 9,\n",
       " 'reverie': 9,\n",
       " 'meadow': 9,\n",
       " 'blue': 9,\n",
       " 'silver': 9,\n",
       " 'river': 9,\n",
       " 'toil': 9,\n",
       " 'archangel': 9,\n",
       " 'activity': 9,\n",
       " 'judgment': 9,\n",
       " 'connexion': 9,\n",
       " 'privilege': 9,\n",
       " 'chimney': 9,\n",
       " 'rage': 9,\n",
       " 'square': 9,\n",
       " 'surgeon': 9,\n",
       " 'adventure': 9,\n",
       " 'surprise': 9,\n",
       " 'attention': 9,\n",
       " 'ease': 9,\n",
       " 'joke': 9,\n",
       " 'cloth': 9,\n",
       " 'grief': 9,\n",
       " 'bosom': 9,\n",
       " 'rumor': 9,\n",
       " 'cheer': 9,\n",
       " 'youth': 9,\n",
       " 'mercy': 9,\n",
       " 'suspicion': 9,\n",
       " 'item': 9,\n",
       " 'alarm': 9,\n",
       " 'token': 9,\n",
       " 'philosopher': 9,\n",
       " 'intensity': 9,\n",
       " 'dollar': 9,\n",
       " 'peace': 9,\n",
       " 'throne': 9,\n",
       " 'intention': 9,\n",
       " 'bowl': 9,\n",
       " 'nostril': 9,\n",
       " 'homage': 9,\n",
       " 'boom': 9,\n",
       " 'panic': 9,\n",
       " 'prospect': 9,\n",
       " 'chief': 9,\n",
       " 'helmsman': 9,\n",
       " 'sailing': 9,\n",
       " 'exclamation': 9,\n",
       " 'loss': 9,\n",
       " 'member': 9,\n",
       " 'hatchway': 9,\n",
       " 'steward': 9,\n",
       " 'apparition': 9,\n",
       " 'cheese': 9,\n",
       " 'courage': 9,\n",
       " 'soil': 9,\n",
       " 'fury': 9,\n",
       " 'argument': 9,\n",
       " 'particular': 9,\n",
       " 'problem': 9,\n",
       " 'blind': 9,\n",
       " 'capstan': 9,\n",
       " 'socket': 9,\n",
       " 'consequence': 9,\n",
       " 'longitude': 9,\n",
       " 'dust': 9,\n",
       " 'thread': 9,\n",
       " 'thigh': 9,\n",
       " 'signal': 9,\n",
       " 'bowsman': 9,\n",
       " 'crotch': 9,\n",
       " 'feeder': 9,\n",
       " 'statement': 8,\n",
       " 'deep': 8,\n",
       " 'serpent': 8,\n",
       " 'grove': 8,\n",
       " 'lie': 8,\n",
       " 'smell': 8,\n",
       " 'note': 8,\n",
       " 'creation': 8,\n",
       " 'property': 8,\n",
       " 'moonlight': 8,\n",
       " 'agony': 8,\n",
       " 'attack': 8,\n",
       " 'entrance': 8,\n",
       " 'colt': 8,\n",
       " 'pistol': 8,\n",
       " 'pine': 8,\n",
       " 'leave': 8,\n",
       " 'handful': 8,\n",
       " 'office': 8,\n",
       " 'scale': 8,\n",
       " 'bill': 8,\n",
       " 'marvel': 8,\n",
       " 'carpet': 8,\n",
       " 'bowsprit': 8,\n",
       " 'nay': 8,\n",
       " 'ray': 8,\n",
       " 'entry': 8,\n",
       " 'masse': 8,\n",
       " 'dim': 8,\n",
       " 'yon': 8,\n",
       " 'beam': 8,\n",
       " 'den': 8,\n",
       " 'meal': 8,\n",
       " 'fare': 8,\n",
       " 'beard': 8,\n",
       " 'plane': 8,\n",
       " 'current': 8,\n",
       " 'stick': 8,\n",
       " 'string': 8,\n",
       " 'hurry': 8,\n",
       " 'eagerness': 8,\n",
       " 'tattooing': 8,\n",
       " 'chapel': 8,\n",
       " 'symptom': 8,\n",
       " 'grinning': 8,\n",
       " 'daylight': 8,\n",
       " 'reality': 8,\n",
       " 'cooper': 8,\n",
       " 'sum': 8,\n",
       " 'rose': 8,\n",
       " 'tablet': 8,\n",
       " 'despair': 8,\n",
       " 'trick': 8,\n",
       " 'well': 8,\n",
       " 'sin': 8,\n",
       " 'apprehension': 8,\n",
       " 'motionless': 8,\n",
       " 'robe': 8,\n",
       " 'desire': 8,\n",
       " 'run': 8,\n",
       " 'third': 8,\n",
       " 'feeding': 8,\n",
       " 'variety': 8,\n",
       " 'energy': 8,\n",
       " 'material': 8,\n",
       " 'pin': 8,\n",
       " 'tent': 8,\n",
       " 'crow': 8,\n",
       " 'pen': 8,\n",
       " 'intent': 8,\n",
       " 'tong': 8,\n",
       " 'thither': 8,\n",
       " 'dawn': 8,\n",
       " 'slide': 8,\n",
       " 'handspike': 8,\n",
       " 'whisker': 8,\n",
       " 'hero': 8,\n",
       " 'vitality': 8,\n",
       " 'superstition': 8,\n",
       " 'vicissitude': 8,\n",
       " 'hundred': 8,\n",
       " 'rack': 8,\n",
       " 'village': 8,\n",
       " 'taffrail': 8,\n",
       " 'tradition': 8,\n",
       " 'oak': 8,\n",
       " 'toe': 8,\n",
       " 'science': 8,\n",
       " 'spouting': 8,\n",
       " 'title': 8,\n",
       " 'structure': 8,\n",
       " 'brute': 8,\n",
       " 'obedience': 8,\n",
       " 'column': 8,\n",
       " 'mention': 8,\n",
       " 'deed': 8,\n",
       " 'lead': 8,\n",
       " 'copper': 8,\n",
       " 'revenge': 8,\n",
       " 'fatality': 8,\n",
       " 'detail': 8,\n",
       " 'disaster': 8,\n",
       " 'tow': 8,\n",
       " 'beauty': 8,\n",
       " 'hum': 8,\n",
       " 'brit': 8,\n",
       " 'steering': 8,\n",
       " 'shower': 8,\n",
       " 'heap': 8,\n",
       " 'canst': 8,\n",
       " 'spiracle': 8,\n",
       " 'calf': 8,\n",
       " 'shot': 8,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(nouns.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQD3Mhr1aftj"
   },
   "source": [
    "# Count Entities\n",
    "\n",
    "1.   Count the number of entities for the following types: PER, LOC and ORG.\n",
    "2.   Order PERsons according to their occurrences.\n",
    "2.   Order LOCation according to their occurrences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56218,
     "status": "ok",
     "timestamp": 1744726994470,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "mxLjEmxKUox5",
    "outputId": "72046add-b826-45e4-9762-725751d04108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249 277 1041\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "per = 0\n",
    "loc = 0\n",
    "org = 0\n",
    "file = open('moby_dick.txt','r')\n",
    "text = \"\"\n",
    "for l in file:\n",
    "  l = l.strip()\n",
    "  if len(l)==0 and len(text)>0:\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "      if ent.label_=='PERSON':\n",
    "        per += 1\n",
    "      elif ent.label_=='LOC':\n",
    "        loc += 1\n",
    "      elif ent.label_=='ORG':\n",
    "        org += 1\n",
    "    text = \"\"\n",
    "  elif len(l)>0:\n",
    "    text += \" \" + l\n",
    "file.close()\n",
    "\n",
    "print('{0} {1} {2}'.format(per, loc, org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55897,
     "status": "ok",
     "timestamp": 1744727050365,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "XiGc93tUj2NQ",
    "outputId": "6ef14d6e-cfe5-4673-d2e9-c58a30738a91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ahab': 464,\n",
       " 'Starbuck': 191,\n",
       " 'Moby Dick': 74,\n",
       " 'Peleg': 72,\n",
       " 'Tashtego': 52,\n",
       " 'Jonah': 46,\n",
       " 'Stubb': 30,\n",
       " 'Fedallah': 28,\n",
       " 'Pip': 21,\n",
       " 'Gabriel': 20,\n",
       " 'Ahab’s': 19,\n",
       " 'Lakeman': 18,\n",
       " 'Bildad': 17,\n",
       " 'Daggoo': 16,\n",
       " 'Perth': 16,\n",
       " 'Leviathan': 13,\n",
       " 'Hussey': 13,\n",
       " 'Cook': 12,\n",
       " 'Ishmael': 12,\n",
       " 'Manxman': 11,\n",
       " 'Dough-Boy': 11,\n",
       " 'Carpenter': 10,\n",
       " 'Scoresby': 10,\n",
       " 'Nantucketers': 10,\n",
       " 'Mapple': 9,\n",
       " 'Yojo': 9,\n",
       " 'Folio': 9,\n",
       " 'Guernsey': 9,\n",
       " 'Whales': 8,\n",
       " 'Jove': 8,\n",
       " 'Flask': 8,\n",
       " 'Octavo': 8,\n",
       " 'Death': 7,\n",
       " 'Hurrah': 7,\n",
       " 'Don Sebastian': 7,\n",
       " 'Mayhew': 7,\n",
       " 'Vishnoo': 7,\n",
       " 'Ho': 7,\n",
       " 'Nantucket': 6,\n",
       " 'Landlord': 6,\n",
       " 'Adam': 6,\n",
       " 'Quohog': 6,\n",
       " 'Thou': 6,\n",
       " 'Sleet': 6,\n",
       " 'Solomon': 6,\n",
       " 'Steelkilt': 6,\n",
       " 'Sperm Whales': 6,\n",
       " 'Line': 6,\n",
       " 'Pip’s': 6,\n",
       " 'Mark': 5,\n",
       " 'Bulkington': 5,\n",
       " 'Joppa': 5,\n",
       " 'Nineveh': 5,\n",
       " 'Duodecimo': 5,\n",
       " 'Tash': 5,\n",
       " 'Archy': 5,\n",
       " 'Don': 5,\n",
       " 'Hindoo': 5,\n",
       " 'Java': 5,\n",
       " 'Derick': 5,\n",
       " 'Cabin': 4,\n",
       " 'Johnson': 4,\n",
       " 'Euroclydon': 4,\n",
       " 'Cadiz': 4,\n",
       " 'Delight': 4,\n",
       " 'Queequeg': 4,\n",
       " 'Owen': 4,\n",
       " 'Belshazzar': 4,\n",
       " 'Manilla': 4,\n",
       " 'Don Pedro': 4,\n",
       " 'Noah': 4,\n",
       " 'Jeroboam': 4,\n",
       " 'caw': 4,\n",
       " 'Bunger': 4,\n",
       " 'Rachel': 4,\n",
       " 'Ibid': 3,\n",
       " 'Bennett': 3,\n",
       " 'Samuel': 3,\n",
       " 'Sabbath': 3,\n",
       " 'Lazarus': 3,\n",
       " 'Czar': 3,\n",
       " 'Sal': 3,\n",
       " 'Nelson': 3,\n",
       " 'Virtue': 3,\n",
       " 'Grace': 3,\n",
       " 'Nantucketer': 3,\n",
       " 'Hosea Hussey': 3,\n",
       " 'Tit': 3,\n",
       " 'Ye': 3,\n",
       " 'Azores': 3,\n",
       " 'Mogul': 3,\n",
       " 'Turk': 3,\n",
       " 'Abraham': 3,\n",
       " 'Prometheus': 3,\n",
       " 'Pollard': 3,\n",
       " 'Procopius': 3,\n",
       " 'lo': 3,\n",
       " 'Rad': 3,\n",
       " 'Perseus': 3,\n",
       " 'Mounttop': 3,\n",
       " 'Boomer': 3,\n",
       " 'Snodhead': 3,\n",
       " 'Tranquo': 3,\n",
       " 'Clifford': 3,\n",
       " 'Mary': 3,\n",
       " 'Bosom Friend': 2,\n",
       " 'Queen Mab': 2,\n",
       " 'Dusk': 2,\n",
       " 'Ahab’s Boat': 2,\n",
       " 'Crew': 2,\n",
       " 'Stubb Kills': 2,\n",
       " 'Stubb’s Supper': 2,\n",
       " 'Honor': 2,\n",
       " 'Jonah Historically Regarded': 2,\n",
       " 'Ambergris': 2,\n",
       " 'Down': 2,\n",
       " 'Ahab’s Leg': 2,\n",
       " 'Blacksmith': 2,\n",
       " 'Forge': 2,\n",
       " 'Forecastle Bulwarks': 2,\n",
       " 'Deck': 2,\n",
       " 'Dan': 2,\n",
       " 'Isaiah': 2,\n",
       " 'T. Browne': 2,\n",
       " 'Harris Coll': 2,\n",
       " 'Goldsmith': 2,\n",
       " 'Edmund Burke': 2,\n",
       " 'Tom': 2,\n",
       " 'Owen Chace': 2,\n",
       " 'lee': 2,\n",
       " 'Steady': 2,\n",
       " 'Gomorrah': 2,\n",
       " 'Sam': 2,\n",
       " 'Peter Coffin': 2,\n",
       " 'Canaan': 2,\n",
       " 'Scriptures': 2,\n",
       " 'Jaffa': 2,\n",
       " 'Moss': 2,\n",
       " 'Cod': 2,\n",
       " 'Cape Cod': 2,\n",
       " 'Tistig': 2,\n",
       " 'Captains': 2,\n",
       " 'John Hunter': 2,\n",
       " 'Frederick Cuvier': 2,\n",
       " 'J. Ross Browne': 2,\n",
       " 'Charley Coffin': 2,\n",
       " 'Grampus': 2,\n",
       " 'Sulphur': 2,\n",
       " 'CHAPTER I.': 2,\n",
       " 'Whalebone': 2,\n",
       " 'CHAPTER V.': 2,\n",
       " 'Killer': 2,\n",
       " 'Dough-Boy’s': 2,\n",
       " 'Heed': 2,\n",
       " 'Farewell': 2,\n",
       " 'Tahiti': 2,\n",
       " 'pell-mell': 2,\n",
       " 'Don Miguel': 2,\n",
       " 'Davis': 2,\n",
       " 'Barbary': 2,\n",
       " '’s lee': 2,\n",
       " 'Canaller': 2,\n",
       " 'Colnett': 2,\n",
       " 'gore': 2,\n",
       " 'Massa Stubb': 2,\n",
       " 'Esquimaux': 2,\n",
       " 'muttered Ahab': 2,\n",
       " 'Gall': 2,\n",
       " 'Derick De Deer': 2,\n",
       " 'humped': 2,\n",
       " 'Yarman': 2,\n",
       " 'Sail': 2,\n",
       " 'Vedas': 2,\n",
       " 'Java Head': 2,\n",
       " 'gaunt': 2,\n",
       " 'Bashaw': 2,\n",
       " 'Woebegone': 2,\n",
       " 'Savesoul': 2,\n",
       " 'Warden': 2,\n",
       " 'Rose-bud': 2,\n",
       " 'Coffin': 2,\n",
       " 'Solomon’s': 2,\n",
       " 'Hem': 2,\n",
       " 'Archer': 2,\n",
       " 'ho': 2,\n",
       " 'Jenny': 2,\n",
       " 'Sammy': 2,\n",
       " 'Samuel Enderby': 2,\n",
       " 'the Samuel Enderby': 2,\n",
       " 'Dan Coopman': 2,\n",
       " 'Fossil Whales': 2,\n",
       " 'John Leo': 2,\n",
       " 'Antilles': 2,\n",
       " 'Jerk': 2,\n",
       " 'Lo': 2,\n",
       " 'Ding': 2,\n",
       " 'dong': 2,\n",
       " 'Gardiner': 2,\n",
       " 'Moby Dick’s': 2,\n",
       " 'Herman Melville': 1,\n",
       " 'Gutenberg': 1,\n",
       " 'Ger': 1,\n",
       " 'Wallen': 1,\n",
       " 'Fegee': 1,\n",
       " 'Erromangoan': 1,\n",
       " 'Pale Sherry': 1,\n",
       " 'Michael': 1,\n",
       " 'Raphael': 1,\n",
       " 'Whirlpooles': 1,\n",
       " 'Balaene': 1,\n",
       " 'Tooke’s Lucian': 1,\n",
       " 'King Alfred': 1,\n",
       " 'Nick': 1,\n",
       " 'King Henry': 1,\n",
       " 'Mote': 1,\n",
       " 'William Davenant': 1,\n",
       " 'Nescio': 1,\n",
       " 'Sperma Ceti': 1,\n",
       " 'V. E.': 1,\n",
       " 'Hobbes’s Leviathan': 1,\n",
       " 'Mirabilis': 1,\n",
       " 'Thomas Edge’s': 1,\n",
       " 'T. Herbert’s Voyages': 1,\n",
       " 'Pitferren': 1,\n",
       " 'Kinross': 1,\n",
       " 'Richard Strafford’s Letter': 1,\n",
       " 'Bermudas': 1,\n",
       " 'Phil': 1,\n",
       " 'N. E. Primer': 1,\n",
       " 'Cowley’s Voyage': 1,\n",
       " 'Nat': 1,\n",
       " 'Cook’s Voyages': 1,\n",
       " 'Nantuckois': 1,\n",
       " 'Thomas Jefferson’s Whale Memorial': 1,\n",
       " 'Edmund Burke’s': 1,\n",
       " 'Falconer’s Shipwreck': 1,\n",
       " 'John Hunter’s': 1,\n",
       " 'Paley’s Theology': 1,\n",
       " 'Spermacetti Whales': 1,\n",
       " 'Colnett’s Voyage': 1,\n",
       " 'Charles Lamb’s Triumph': 1,\n",
       " 'Susan': 1,\n",
       " 'Hawthorne’s': 1,\n",
       " 'Chace': 1,\n",
       " 'Elizabeth Oakes Smith': 1,\n",
       " 'Thomas Beale’s History': 1,\n",
       " 'Frederick Debell Bennett’s': 1,\n",
       " 'J. Ross Browne’s': 1,\n",
       " 'Lay': 1,\n",
       " 'Webster': 1,\n",
       " 'Daniel Webster’s Speech': 1,\n",
       " 'Henry T. Cheever': 1,\n",
       " 'Samuel Comstock': 1,\n",
       " 'William Comstock': 1,\n",
       " 'Currents': 1,\n",
       " 'U.S. Ex': 1,\n",
       " 'Newspaper Account': 1,\n",
       " 'Cruise': 1,\n",
       " 'Miriam Coffin': 1,\n",
       " 'Darwin’s Voyage': 1,\n",
       " 'Wharton': 1,\n",
       " 'Nantucket Song': 1,\n",
       " 'Whale Song': 1,\n",
       " 'Niagara': 1,\n",
       " 'Narcissus': 1,\n",
       " 'thing;—no': 1,\n",
       " 'Randolphs': 1,\n",
       " 'Peter': 1,\n",
       " 'silken wrapper—(he': 1,\n",
       " 'Nathan Swain': 1,\n",
       " 'I. “Where': 1,\n",
       " '’s Bulkington': 1,\n",
       " 'Skrimshander': 1,\n",
       " 'Johnny': 1,\n",
       " 'I. “Landlord': 1,\n",
       " 'Rogers': 1,\n",
       " 'shaggy': 1,\n",
       " 'satin wood': 1,\n",
       " 'Grub': 1,\n",
       " 'Chestnut': 1,\n",
       " 'Herr Alexander': 1,\n",
       " 'NATHAN COLEMAN': 1,\n",
       " 'SAMUEL GLEIG': 1,\n",
       " 'MARBLE': 1,\n",
       " 'snowy breakers': 1,\n",
       " 'Amittai': 1,\n",
       " 'Tarshish': 1,\n",
       " 'Joe': 1,\n",
       " 'Harry': 1,\n",
       " 'Startled': 1,\n",
       " 'Jonah’s': 1,\n",
       " 'Straightway': 1,\n",
       " 'Jonah’s sea-storm': 1,\n",
       " 'Falsehood': 1,\n",
       " 'Gospel': 1,\n",
       " 'Woe': 1,\n",
       " 'Paul': 1,\n",
       " 'kelson': 1,\n",
       " 'George Washington': 1,\n",
       " 'worship?—to': 1,\n",
       " 'seaward': 1,\n",
       " 'Czar Peter': 1,\n",
       " 'Peter Coffin’s': 1,\n",
       " 'King': 1,\n",
       " 'Humane': 1,\n",
       " 'Magnanimous Societies': 1,\n",
       " 'Eddystone': 1,\n",
       " 'Laplander': 1,\n",
       " 'Mastodon': 1,\n",
       " 'Cousin Hosea': 1,\n",
       " 'inn': 1,\n",
       " 'Shirt': 1,\n",
       " 'Hosea': 1,\n",
       " 'Stiggs': 1,\n",
       " 'Yojo’s': 1,\n",
       " 'XXXIX Articles': 1,\n",
       " 'Pottowottamie Sachem’s': 1,\n",
       " 'Quakerish Nantucketer': 1,\n",
       " 'Pagan Roman': 1,\n",
       " 'leviathan gore': 1,\n",
       " 'the Thunder Cloud': 1,\n",
       " 'Ishmael’s': 1,\n",
       " 'Betty': 1,\n",
       " 'Hygiene': 1,\n",
       " 'Deacon Deuteronomy': 1,\n",
       " 'Nat Swaine': 1,\n",
       " 'hav’n’t': 1,\n",
       " 'Ye hav’n’t': 1,\n",
       " 'I. “Come along': 1,\n",
       " 'Lookee': 1,\n",
       " 'Elijah': 1,\n",
       " 'perry dood': 1,\n",
       " 'Shipped': 1,\n",
       " 'Blood': 1,\n",
       " 'Lank Bildad': 1,\n",
       " 'Stand': 1,\n",
       " 'Jordan': 1,\n",
       " 'Louis XVI': 1,\n",
       " 'Benjamin Franklin': 1,\n",
       " 'Mary Morrel': 1,\n",
       " 'Mary Folger': 1,\n",
       " 'kith': 1,\n",
       " 'Benjamin': 1,\n",
       " 'Whaling': 1,\n",
       " 'Bunyan': 1,\n",
       " 'Cervantes': 1,\n",
       " 'Andrew Jackson': 1,\n",
       " 'Gay Head': 1,\n",
       " 'Ahasuerus Daggoo': 1,\n",
       " 'Herein': 1,\n",
       " 'Isolato': 1,\n",
       " 'Old Ahab': 1,\n",
       " 'Earls': 1,\n",
       " 'Khan': 1,\n",
       " 'Humpback': 1,\n",
       " 'I. ‘': 1,\n",
       " 'Surgeon Beale': 1,\n",
       " 'Lesson': 1,\n",
       " 'Thomas Browne': 1,\n",
       " 'Gesner': 1,\n",
       " 'Ray': 1,\n",
       " 'Willoughby': 1,\n",
       " 'Sibbald': 1,\n",
       " 'Brisson': 1,\n",
       " 'Bonneterre': 1,\n",
       " 'Desmarest': 1,\n",
       " 'Olmstead': 1,\n",
       " 'T. Cheever': 1,\n",
       " 'whaleman': 1,\n",
       " 'penem intrantem feminam mammis': 1,\n",
       " 'Simeon Macey': 1,\n",
       " 'Charley': 1,\n",
       " 'Dugongs': 1,\n",
       " 'Cachalot': 1,\n",
       " 'Razor Back_).—Of': 1,\n",
       " 'Adieu': 1,\n",
       " 'Sulphur Bottom': 1,\n",
       " 'Thrasher': 1,\n",
       " 'Martin Frobisher': 1,\n",
       " 'Queen Bess': 1,\n",
       " 'Martin': 1,\n",
       " 'the Earl of Leicester': 1,\n",
       " 'Bonapartes': 1,\n",
       " 'Sharks': 1,\n",
       " 'WHALES': 1,\n",
       " 'Huzza': 1,\n",
       " 'Huzza Porpoise': 1,\n",
       " 'Algerine': 1,\n",
       " 'Mealy': 1,\n",
       " 'Porpoise': 1,\n",
       " 'Iceberg Whale': 1,\n",
       " 'Dutch Fishery': 1,\n",
       " 'Harpooneer': 1,\n",
       " 'Mesopotamian': 1,\n",
       " 'Kings': 1,\n",
       " 'Belshazzar’s': 1,\n",
       " 'Saint Stylites': 1,\n",
       " 'Louis Philippe': 1,\n",
       " 'Louis Blanc': 1,\n",
       " 'Great Washington': 1,\n",
       " 'Colossus': 1,\n",
       " 'Rhodes': 1,\n",
       " 'Childe Harold': 1,\n",
       " 'Good Hope': 1,\n",
       " 'Steward': 1,\n",
       " 'Pope': 1,\n",
       " 'Forthwith': 1,\n",
       " 'Burkes': 1,\n",
       " 'Foresail': 1,\n",
       " 'Sings': 1,\n",
       " 'Mogul’s': 1,\n",
       " 'Ascending': 1,\n",
       " 'Dancing': 1,\n",
       " 'Bang': 1,\n",
       " 'Rig': 1,\n",
       " 'Jinglers': 1,\n",
       " 'Merry-mad': 1,\n",
       " 'Seeva': 1,\n",
       " 'Nudging': 1,\n",
       " 'JAGO': 1,\n",
       " 'Spaniard’s': 1,\n",
       " 'arrah': 1,\n",
       " 'Jimmini': 1,\n",
       " 'events,—as': 1,\n",
       " 'Baron': 1,\n",
       " 'Siam': 1,\n",
       " 'Pizarro': 1,\n",
       " 'bison herds': 1,\n",
       " 'Grin': 1,\n",
       " 'Lieutenant Maury': 1,\n",
       " 'Rinaldo Rinaldini': 1,\n",
       " 'Nay': 1,\n",
       " 'Jack': 1,\n",
       " 'Sylla': 1,\n",
       " 'Butler': 1,\n",
       " 'Annawon': 1,\n",
       " 'Saul': 1,\n",
       " 'Langsdorff’s Voyages': 1,\n",
       " 'Langsdorff': 1,\n",
       " 'D’Wolf': 1,\n",
       " 'Lionel Wafer': 1,\n",
       " 'John Ferdinando': 1,\n",
       " 'Juan Fernandes': 1,\n",
       " 'Pusie Hall': 1,\n",
       " 'Justinian': 1,\n",
       " 'Marmora': 1,\n",
       " 'barbaric majesty': 1,\n",
       " 'Roar': 1,\n",
       " 'know;—merry': 1,\n",
       " 'Spring': 1,\n",
       " 'Squall': 1,\n",
       " 'Rabbins': 1,\n",
       " 'Mysteriously': 1,\n",
       " 'Crozetts': 1,\n",
       " 'Noah Webster’s': 1,\n",
       " 'Dons': 1,\n",
       " 'Pedro': 1,\n",
       " 'Sebastian': 1,\n",
       " 'Golden Inn': 1,\n",
       " 'Bowie': 1,\n",
       " 'Steelkilt Charlemagne': 1,\n",
       " 'Radney': 1,\n",
       " 'Erie Canal': 1,\n",
       " 'Mark Antony': 1,\n",
       " 'Sydney': 1,\n",
       " 'Jesu': 1,\n",
       " 'Spaniards': 1,\n",
       " 'Don Sebastian’s': 1,\n",
       " 'Saladin’s': 1,\n",
       " 'Brahmins': 1,\n",
       " 'Vishnu': 1,\n",
       " 'Guido': 1,\n",
       " 'Hogarth': 1,\n",
       " 'Scotch Sibbald': 1,\n",
       " 'Harris': 1,\n",
       " 'Jonas': 1,\n",
       " 'Peter Peterson': 1,\n",
       " 'Bernard Germain': 1,\n",
       " 'Frederick Cuvier’s Sperm Whale': 1,\n",
       " 'Richard III': 1,\n",
       " 'whales': 1,\n",
       " 'Jeremy Bentham’s': 1,\n",
       " 'Jeremy': 1,\n",
       " 'Hunter': 1,\n",
       " 'Colnett’s': 1,\n",
       " 'Frederick Cuvier’s': 1,\n",
       " 'H. Durand': 1,\n",
       " 'Sag Harbor': 1,\n",
       " 'Achilles’s': 1,\n",
       " 'Albert Durer': 1,\n",
       " 'Mendanna': 1,\n",
       " 'Figuera': 1,\n",
       " 'Korah': 1,\n",
       " 'Push': 1,\n",
       " 'Calais': 1,\n",
       " 'Mazeppa': 1,\n",
       " 'Koo-loo': 1,\n",
       " 'Fleece': 1,\n",
       " 'Ebony': 1,\n",
       " 'Belubed': 1,\n",
       " 'dan de shark': 1,\n",
       " 'Gor': 1,\n",
       " 'Kick up de damndest row': 1,\n",
       " 'joosy': 1,\n",
       " 'berry joosy': 1,\n",
       " 'Drop': 1,\n",
       " 'dan Massa Shark': 1,\n",
       " 'Dunfermline': 1,\n",
       " 'Zogranda': 1,\n",
       " 'Englishmen': 1,\n",
       " 'Ingin': 1,\n",
       " 'Borneo': 1,\n",
       " 'exclaimed—“That': 1,\n",
       " 'Oceanica': 1,\n",
       " 'Ahab answered—“Aye': 1,\n",
       " 'Har': 1,\n",
       " 'Harry—(a': 1,\n",
       " 'Harry Macey': 1,\n",
       " 'Ahab’s feet': 1,\n",
       " 'Right Whales': 1,\n",
       " 'Israelites': 1,\n",
       " 'John': 1,\n",
       " 'John the': 1,\n",
       " 'Kant': 1,\n",
       " 'Herschel': 1,\n",
       " 'Queen Anne': 1,\n",
       " 'Heidelburgh Tun': 1,\n",
       " 'ninetieth bucket': 1,\n",
       " 'Avast': 1,\n",
       " 'Lavater': 1,\n",
       " 'Shakespeare': 1,\n",
       " 'Lavater’s': 1,\n",
       " 'William Jones': 1,\n",
       " 'Halloo': 1,\n",
       " 'Gayhead': 1,\n",
       " 'portcullis jaw': 1,\n",
       " 'layeth': 1,\n",
       " 'laugheth': 1,\n",
       " 'Haul': 1,\n",
       " 'Jungfrau': 1,\n",
       " 'Virgin': 1,\n",
       " 'Andromeda': 1,\n",
       " 'Hercules': 1,\n",
       " 'Kit Carson': 1,\n",
       " 'Greeks': 1,\n",
       " 'Bishop Jebb’s': 1,\n",
       " 'Bartholomew Diaz': 1,\n",
       " 'Sag-Harbor': 1,\n",
       " 'Harris’s Voyages': 1,\n",
       " 'Yea': 1,\n",
       " 'Dante': 1,\n",
       " 'Eckerman': 1,\n",
       " 'Angelo': 1,\n",
       " 'Ptolemy Philopater': 1,\n",
       " 'King Juba': 1,\n",
       " 'bush': 1,\n",
       " 'rear,—than': 1,\n",
       " 'Alexander': 1,\n",
       " 'Gulfweed': 1,\n",
       " 'Arnold': 1,\n",
       " 'Riotous': 1,\n",
       " 'scolloped fins': 1,\n",
       " 'Lothario': 1,\n",
       " 'Daniel Boone': 1,\n",
       " 'Nature': 1,\n",
       " 'Erskine': 1,\n",
       " 'Ellenborough': 1,\n",
       " 'Lord Ellenborough': 1,\n",
       " 'John Bull': 1,\n",
       " 'Jonathan': 1,\n",
       " 'Bracton': 1,\n",
       " 'Honorary Grand Harpooneer': 1,\n",
       " 'Plowdon': 1,\n",
       " 'William Prynne': 1,\n",
       " 'Queen’s': 1,\n",
       " 'Queen': 1,\n",
       " 'Prynne': 1,\n",
       " 'V.E.': 1,\n",
       " 'shun': 1,\n",
       " 'Bouton': 1,\n",
       " 'Brandreth': 1,\n",
       " 'Paracelsus': 1,\n",
       " 'Icy Seas': 1,\n",
       " 'Schmerenburgh': 1,\n",
       " 'Smeerenberg': 1,\n",
       " 'Alexander the Great': 1,\n",
       " 'nick-name': 1,\n",
       " 'Leap': 1,\n",
       " 'Berkshire': 1,\n",
       " 'Gurry': 1,\n",
       " 'Queen Maachah': 1,\n",
       " 'viciously spat': 1,\n",
       " 'I. Lo': 1,\n",
       " 'Rousseau': 1,\n",
       " 'Abednego': 1,\n",
       " 'Spanishly': 1,\n",
       " 'Lucifer': 1,\n",
       " 'Bowditch': 1,\n",
       " 'Jimimi': 1,\n",
       " 'Gemini': 1,\n",
       " 'Doubloon': 1,\n",
       " 'Leo': 1,\n",
       " 'Lion': 1,\n",
       " 'Libra': 1,\n",
       " 'Zodiac': 1,\n",
       " 'Murray’s Grammar': 1,\n",
       " 'Hish': 1,\n",
       " 'hish': 1,\n",
       " 'Jump': 1,\n",
       " '—Mounttop': 1,\n",
       " 'Ahab—“is': 1,\n",
       " 'Jack Bunger': 1,\n",
       " 'Divine Providence': 1,\n",
       " 'jack-knives': 1,\n",
       " 'Coffins': 1,\n",
       " 'Maceys': 1,\n",
       " 'Rattler': 1,\n",
       " 'Saxon': 1,\n",
       " 'Flip': 1,\n",
       " 'Fitz Swackhammer': 1,\n",
       " 'Smeer': 1,\n",
       " 'Texel': 1,\n",
       " 'Hitherto': 1,\n",
       " 'hose': 1,\n",
       " 'jack-knife': 1,\n",
       " 'Damocles': 1,\n",
       " 'Burton Constable': 1,\n",
       " 'Clifford Constable': 1,\n",
       " 'Tranquo’s': 1,\n",
       " 'Creagh': 1,\n",
       " 'Zeuglodon': 1,\n",
       " 'Methuselah': 1,\n",
       " 'Shem': 1,\n",
       " 'marl': 1,\n",
       " 'Denderah': 1,\n",
       " 'Matter': 1,\n",
       " 'Rib': 1,\n",
       " 'Prophet': 1,\n",
       " 'Prophet Jonas': 1,\n",
       " 'Aldrovandus': 1,\n",
       " 'Banks': 1,\n",
       " 'Iceland Whales': 1,\n",
       " 'Lacépède': 1,\n",
       " 'Harto': 1,\n",
       " 'Goa': 1,\n",
       " 'the King of Siam': 1,\n",
       " 'Porus': 1,\n",
       " 'Windsor Castle': 1,\n",
       " 'Noah’s Ark': 1,\n",
       " 'Smut': 1,\n",
       " 'Mogulship': 1,\n",
       " '’s Prometheus': 1,\n",
       " 'carpenter;—or': 1,\n",
       " 'Matsmai': 1,\n",
       " 'me?—On': 1,\n",
       " 'murmured Ahab': 1,\n",
       " 'Aristotle': 1,\n",
       " 'Zoroaster': 1,\n",
       " 'behind;—I': 1,\n",
       " 'flaxen curls': 1,\n",
       " 'Remote': 1,\n",
       " 'blacksmith': 1,\n",
       " 'Said': 1,\n",
       " 'Ahoy': 1,\n",
       " 'Yonder': 1,\n",
       " 'Mene': 1,\n",
       " 'Sudden': 1,\n",
       " 'Yoke': 1,\n",
       " 'Twill': 1,\n",
       " 'frock.—Ahab': 1,\n",
       " 'Gallipagos': 1,\n",
       " 'Manx': 1,\n",
       " 'Lad': 1,\n",
       " 'miles,—ahead': 1,\n",
       " 'Tanaquil': 1,\n",
       " 'Hither': 1,\n",
       " 'Miriam': 1,\n",
       " 'Martha': 1,\n",
       " 'Behold': 1,\n",
       " 'yon Albicore': 1,\n",
       " 'Mate': 1,\n",
       " 'Luff': 1,\n",
       " 'lower,—quick': 1,\n",
       " 'her!—shiver her!—So': 1,\n",
       " 'Boats': 1,\n",
       " 'Groan': 1,\n",
       " 'Jesus': 1,\n",
       " 'Twas': 1,\n",
       " 'Tis Ahab': 1,\n",
       " 'Mississippies': 1,\n",
       " 'Leeward': 1,\n",
       " 'Away': 1,\n",
       " 'Fata Morgana': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "file = open('moby_dick.txt','r')\n",
    "text = \"\"\n",
    "pers = {}\n",
    "for l in file:\n",
    "  l = l.strip()\n",
    "  if len(l)==0 and len(text)>0:\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "      if ent.label_=='PERSON':\n",
    "        if ent.text in pers:\n",
    "          pers[ent.text] = pers[ent.text] + 1\n",
    "        else:\n",
    "          pers[ent.text] = 1\n",
    "    text = \"\"\n",
    "  elif len(l)>0:\n",
    "    text += \" \" + l\n",
    "file.close()\n",
    "\n",
    "{k: v for k, v in sorted(pers.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54999,
     "status": "ok",
     "timestamp": 1744727105351,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "liY7dlJsmh11",
    "outputId": "7ccabe1d-d5d0-45d7-c562-b5b719527905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pacific': 29,\n",
       " 'Atlantic': 16,\n",
       " 'Cape Horn': 15,\n",
       " 'Africa': 8,\n",
       " 'Mediterranean': 8,\n",
       " 'New England': 7,\n",
       " 'Andes': 7,\n",
       " 'West': 7,\n",
       " 'East': 7,\n",
       " 'North': 6,\n",
       " 'Asia': 5,\n",
       " 'South': 5,\n",
       " 'Cape': 5,\n",
       " 'South Sea': 5,\n",
       " 'Europe': 4,\n",
       " 'Jupiter': 4,\n",
       " 'Arctic': 4,\n",
       " 'the Cape of Good Hope': 4,\n",
       " 'Temple': 4,\n",
       " 'the South Seas': 3,\n",
       " 'Highland': 3,\n",
       " 'Straits': 3,\n",
       " 'Crotch': 2,\n",
       " 'Io': 2,\n",
       " 'the Polar Sea': 2,\n",
       " 'the Pacific Ocean': 2,\n",
       " 'Queequeg': 2,\n",
       " 'Siberia': 2,\n",
       " 'the Indian Ocean': 2,\n",
       " 'Alps': 2,\n",
       " 'Horn': 2,\n",
       " 'Hull': 2,\n",
       " 'South-Sea': 2,\n",
       " 'Porpoise': 2,\n",
       " 'the Huzza Porpoise': 2,\n",
       " 'Baltic': 2,\n",
       " 'Hudson': 2,\n",
       " 'the Persian Gulf': 2,\n",
       " 'the Town-Ho': 2,\n",
       " 'St. George’s': 2,\n",
       " 'Sea': 2,\n",
       " 'Long Island': 2,\n",
       " 'Shetland': 1,\n",
       " 'Sperma': 1,\n",
       " 'the Pacific ocean': 1,\n",
       " 'the Northern Ocean': 1,\n",
       " 'the Arctic Ocean': 1,\n",
       " 'Hardicanutes': 1,\n",
       " 'the Black Sea': 1,\n",
       " 'the Cape of Blanco': 1,\n",
       " 'Battery': 1,\n",
       " 'Mt. Hecla': 1,\n",
       " 'the Green Mountains': 1,\n",
       " 'Green Mountains': 1,\n",
       " 'the Isle of Desolation': 1,\n",
       " 'the Straits of Gibraltar': 1,\n",
       " 'arctic crystal': 1,\n",
       " 'Sultan': 1,\n",
       " 'Vineyard': 1,\n",
       " 'the Atlantic Ocean': 1,\n",
       " 'the Cape Horn': 1,\n",
       " 'Island': 1,\n",
       " 'South Sea Voyages': 1,\n",
       " 'the Pacific coast': 1,\n",
       " 'the Shetland Islands': 1,\n",
       " 'the Cape Whale': 1,\n",
       " 'Bay': 1,\n",
       " 'the sharkish sea': 1,\n",
       " 'Blanket Bay': 1,\n",
       " 'Antarctic': 1,\n",
       " 'the Rocky Mountains': 1,\n",
       " 'the White Mountains': 1,\n",
       " 'the White Sea': 1,\n",
       " 'the Yellow Sea': 1,\n",
       " 'Central Europe': 1,\n",
       " 'Seychelle': 1,\n",
       " 'Volcano Bay': 1,\n",
       " 'the Japanese Coast': 1,\n",
       " 'Zodiac': 1,\n",
       " 'the Bengal Bay': 1,\n",
       " 'the black sea': 1,\n",
       " 'Salisbury Plain': 1,\n",
       " 'Lake Erie': 1,\n",
       " 'the Northern Lights': 1,\n",
       " 'the Soloma Islands': 1,\n",
       " 'Cape-Down': 1,\n",
       " 'the Southern Fishery': 1,\n",
       " 'the Upper Mississippi': 1,\n",
       " 'the pleasant sea': 1,\n",
       " 'Crozetts': 1,\n",
       " 'Nile': 1,\n",
       " 'Sag-Harbor': 1,\n",
       " 'the Mediterranean Sea': 1,\n",
       " 'Red Sea': 1,\n",
       " 'Javan': 1,\n",
       " 'Sahara': 1,\n",
       " 'the Milky Way': 1,\n",
       " 'west': 1,\n",
       " 'South America': 1,\n",
       " 'Negro Hill': 1,\n",
       " 'Enderbys': 1,\n",
       " 'the South Sea': 1,\n",
       " 'the Spitzbergen sea': 1,\n",
       " 'Bamboo-Town': 1,\n",
       " 'the Rue Dauphine': 1,\n",
       " 'Whale': 1,\n",
       " 'Americas': 1,\n",
       " 'Delta': 1,\n",
       " 'Wild': 1,\n",
       " 'the White Whale': 1,\n",
       " 'the Icy Sea': 1,\n",
       " 'gloom—“Hemp': 1,\n",
       " 'rocky Isle of Man': 1,\n",
       " 'the Isle of Man': 1,\n",
       " 'Manxman': 1,\n",
       " 'Equatorial': 1,\n",
       " 'arctic': 1,\n",
       " 'Paradise': 1,\n",
       " 'Europa': 1,\n",
       " 'the South sea': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "file = open('moby_dick.txt','r')\n",
    "text = \"\"\n",
    "locs = {}\n",
    "for l in file:\n",
    "  l = l.strip()\n",
    "  if len(l)==0 and len(text)>0:\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "      if ent.label_=='LOC':\n",
    "        if ent.text in locs:\n",
    "          locs[ent.text] = locs[ent.text] + 1\n",
    "        else:\n",
    "          locs[ent.text] = 1\n",
    "    text = \"\"\n",
    "  elif len(l)>0:\n",
    "    text += \" \" + l\n",
    "file.close()\n",
    "\n",
    "{k: v for k, v in sorted(locs.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7stnhdEG1otz"
   },
   "source": [
    "Extending spaCy\n",
    "----------------------\n",
    "\n",
    "The entire spaCy architecture is built upon three building blocks: Document (the big encompassing container), Token (most of the time, a word) and Span (set of consecutive Tokens). The extensions you create can add extra functionality to anyone of the these components. There are some examples out there for what you can do. Let’s create an extension ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv0DySlx1y81"
   },
   "source": [
    "### Creating Document level Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1362,
     "status": "ok",
     "timestamp": 1744727106699,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "RMQObGdN1uSV",
    "outputId": "031aa50e-761d-43b2-8bce-80191abc325c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.693, 'pos': 0.307, 'compound': 0.6114}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "#SentimentIntensityAnalyzer is used \n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define the function that implements the new extension (sentiment analysis)\n",
    "def polarity_scores(doc):\n",
    "    return sentiment_analyzer.polarity_scores(doc.text)\n",
    "\n",
    "# Set the new extension. We are addaind a new component to the pipeline of the Doc object\n",
    "Doc.set_extension('polarity_scores', getter=polarity_scores, force=True)\n",
    "\n",
    "doc = nlp(\"Today, there is the sun and it is a wonderful day!\")\n",
    "print(doc._.polarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1744727106726,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "183lR9H945sx",
    "outputId": "fc4d7351-634f-449f-853b-287b940a49b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.449, 'pos': 0.551, 'compound': 0.5684}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Today is a nice day!!!\")\n",
    "print(doc._.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1744727106791,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "x0YIxQZWmuZv",
    "outputId": "5b9d770a-b58d-4754-ce40-88f46b709bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.433, 'neu': 0.343, 'pos': 0.223, 'compound': -0.5346}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love my dog, but I hate cats.\")\n",
    "print(doc._.polarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBidAVbO13iP"
   },
   "source": [
    "One can easily create extensions for every component type. Such extensions only have access to the context of that component. What happens if you need the tokenized text along with the Part-Of-Speech tags. Let’s now build a custom pipeline. Pipelines are another important abstraction of spaCy. The nlp object goes through a list of pipelines and runs them on the document. For example the tagger is ran first, then the parser and ner pipelines are applied on the already POS annotated document. Here’s how the nlp default pipeline structure looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744727106792,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "taOTb6yq16PB",
    "outputId": "eb24f3d5-bd14-4cc8-ea17-00aac46ade3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f9231eafd10>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f9231eaf950>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f92cdd3d700>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f9231f91750>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f9231c920d0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f92ec3fa880>)]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swF1evPI3WQd"
   },
   "source": [
    "### Creating a custom pipeline\n",
    "\n",
    "Let’s build a custom pipeline that needs to be applied after the tagger pipeline is ran. We need the POS tags to get the Synset from Wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1744727106808,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "fP2BLM9O3YlX",
    "outputId": "4d049605-4e9b-4ee1-ab1b-0d52e3732884"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from spacy.tokens import Token\n",
    "from spacy.language import Language\n",
    "\n",
    "\n",
    "\n",
    "# Convert between spaCy PoS tag-set and WordNet PoS tag-set\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "\n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "\n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "    return None\n",
    "\n",
    "# Define a class that implements the new component into the pipeline\n",
    "class WordnetPipeline(object):\n",
    "    def __init__(self, nlp):\n",
    "        Token.set_extension('synset', default=None, force=True)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        for token in doc:\n",
    "            wn_tag = penn_to_wn(token.tag_)\n",
    "            if wn_tag is None:\n",
    "                continue\n",
    "            # We take only the first meaning\n",
    "            ss = wn.synsets(token.text, wn_tag)[0]\n",
    "            token._.set('synset', ss)\n",
    "\n",
    "        return doc\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Python decorators allow you to modify or extend the behavior of functions and methods\n",
    "@Language.factory(\"wordnet_pipe\")\n",
    "def wordnet_pipe(nlp, name):\n",
    "    return WordnetPipeline(nlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLLELR7eq3oq"
   },
   "source": [
    "Setup the new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4291,
     "status": "ok",
     "timestamp": 1744727111100,
     "user": {
      "displayName": "Pierpaolo Basile",
      "userId": "07888937177955634695"
     },
     "user_tz": -120
    },
    "id": "0PMTLTuQq5s7",
    "outputId": "cfafd6bd-d566-4787-8d80-0796191dbd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris NNP Synset('paris.n.01')\n",
      "is VBZ Synset('be.v.01')\n",
      "the DT None\n",
      "awesome JJ Synset('amazing.s.02')\n",
      "capital NN Synset('capital.n.01')\n",
      "of IN None\n",
      "France NNP Synset('france.n.01')\n",
      ". . None\n",
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f9231eafd10>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f9231eaf950>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f92cdd3d700>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f9231f91750>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f9231c920d0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f92ec3fa880>), ('wordnet_pipe', <__main__.WordnetPipeline object at 0x7f9223e9fd10>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('wordnet_pipe', <__main__.WordnetPipeline at 0x7f9223e9fd10>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"wordnet_pipe\")\n",
    "doc = nlp(\"Paris is the awesome capital of France.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.tag_, token._.synset)\n",
    "\n",
    "# Let’s see how the pipeline structure looks like\n",
    "print(nlp.pipeline)\n",
    "\n",
    "nlp.remove_pipe(\"wordnet_pipe\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
